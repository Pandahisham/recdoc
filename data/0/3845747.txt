Extracting Computational and Semantic Features from Portable Chest X-rays for Diagnosis of Acute Respiratory Distress Syndrome

Acute respiratory distress syndrome (ARDS) is a severe inflammatory lung disease with high mortality risk. Development of new and effective therapies for ARDS has been slow due to a lack of precision in its diagnostic criteria. We report preliminary research to extract computational and semantic features directly from chest X-ray images that are used to train machine learning classifiers. Our approach demonstrates the feasibility of using machine learning to identify radiographic criteria that are more consistent and accurate for the diagnosis of ARDS.

ARDS is characterized by an acute onset of diffuse lung injury, hypoxemia, and bilateral infiltrates on chest x-ray (CXR). However, the radiographic criterion of “bilateral infiltrates” is qualitative and lacks precision, leading to poor agreement among clinicians regarding which CXRs are consistent with a diagnosis of ARDS (kappa = 0.55)1. This results in inconsistent clinical practices, and difficulty recruiting patients into clinical trials. Electronic medical record (EMR) data have been used to identify patients who meet diagnostic criteria for ARDS2. However, the utilization of these data, such as radiology reports, generally rely on text mining, which is impeded by a lack of standardized terminology and limited availability online. We propose that direct extraction of computational and semantic features from CXR images can provide an automated and objective way of diagnosing ARDS.
We obtained de-identified portable CXR images from 22 adult patients (10 ARDS, 12 non-ARDS) at Stanford University Medical Center. Two physicians with experience in ARDS diagnosis and management labeled the images (ARDS vs. no ARDS) by consensus. We manually extracted seven semantic features (presence of endotracheal tubes, chest tubes, central venous catheters, nasogastric tubes, ECG leads, focal infiltrates, and lung field opacification). A limited subset of semantic features included all but the most subjective of these (lung field opacification). For computational feature extraction, we manually segmented the lungs, and used their pixels to compute five general-purpose intensity-based imaging features (peak and standard deviation of pixel values, Otsu threshold effectiveness, histogram ratio, and entropy). We used leave-one-out cross validation to train and test four different machine learning classifiers: naive Bayes (NB), k-nearest neighbor (kNN), support vector machines (SVM), and discriminant analysis. We compared the performance of these classifiers to majority rule.
Intensity-based imaging features alone did not distinguish ARDS from non-ARDS. Semantic features performed better than computational features, with a maximum accuracy of 91% using the SVM classifier. Feature selection identified the degree of lung field opacification and the presence of chest tubes to be the most predictive features for the identification of ARDS.
We conducted a pilot study of computational classification of CXRs in ARDS using imaging features. We found that semantic features can aid in the diagnosis of ARDS, and that they perform better than intensity-based computational features. Our preliminary results suggest future steps, including validation of the most predictive features using causal effect analysis, development of automated lung segmentation techniques and methods for improving quantification of semantic features and performance of computational features. Validation of the method in a larger image corpus is also required.

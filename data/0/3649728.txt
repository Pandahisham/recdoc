Implications of Malaria On Iron Deficiency Control Strategies123

The populations in greatest need of iron supplementation are also those at greatest risk of malaria: pregnant women and young children. Iron supplementation has been shown to increase malaria risk in these groups in numerous studies, although this effect is likely diminished by factors such as host immunity, host iron status, and effective malaria surveillance and control. Conversely, the risk of anemia is increased by malaria infections and preventive measures against malaria decrease anemia prevalence in susceptible populations without iron supplementation. Studies have shown that subjects with malaria experience diminished absorption of orally administered iron, so that as a consequence, iron supplementation may have generally reduced efficacy in malarious populations. A possible mechanistic link between malaria, poor absorption of iron, and anemia is provided by recent research on hepcidin, the human iron control hormone. Our improved understanding of iron metabolism may contribute to the control of malaria and the treatment of anemia. Malaria surveillance and control are necessary components of programs to control iron deficiency and may enhance the efficacy of iron supplementation.

For a decade or more, controversy has persisted over whether the benefit of iron supplementation in vulnerable individuals in malaria-endemic areas outweighs a possible increase in risk of malarial infection. A recent Cochrane review suggests that iron is not harmful when “regular malaria surveillance and treatment services are provided” (1). An updated version of this review concurred that across all studies, iron did not increase malaria risk, but the authors qualified this view by stating that there was a significantly increased risk of malaria associated with iron supplementation in areas without adequate malaria surveillance and treatment programs (2). Both Cochrane reviews and the many studies that preceded or followed them still leave nutritionists asking to what extent must malaria be prevalent and surveillance and treatment programs inadequate before it is no longer safe to provide iron supplementation. Are there other, safer methods of addressing the problem of widespread anemia? Aside from the risk of increased malaria, is iron supplementation in a population highly at risk of infection likely to be efficacious and why or why not?
Simultaneously, novel research into iron biology has in the past 10 y vastly increased our understanding of iron metabolism and its interactions with infection. Significantly, the small molecule hepcidin has been identified as a crucial controller of iron bioavailability. This review attempts to synthesize what is known about the links between iron and malaria as well as exploring the underlying mechanisms that might explain them.
The target populations for iron supplementation are exactly those most susceptible to malaria: pregnant women and children. It has long been unclear whether iron supplementation renders children and pregnant women more vulnerable to malarial infections. Global attention to this problem was sparked by the Pemba trial, which was prematurely ended when iron and folic acid supplementation was shown to be associated with a statistically significant increase in the risk of malaria infection and death in children (3). Many subsequent trials appeared to contradict the findings of the Pemba trial (4–6). In an attempt to unify the apparently disparate results, the first Cochrane review examined all available evidence and concluded that, in the presence of malaria surveillance and treatment, iron was not responsible for an increased risk of malaria illness or death (1, 2). The updated review agreed that “oral iron supplementation alone did not increase the risk for clinical malaria” but also cautioned that “an increased risk for any malaria-related clinical event existed when regular malaria surveillance and treatment were not available” (2).
The conclusions of either review do not necessarily answer the pressing questions previously detailed. Although “improvements in prevention and management of malaria have occurred in the last decade in sub-Saharan Africa, allowing for iron supplementation in safer setting than ever before” (2), malaria surveillance and treatment remain inadequate in many malaria-endemic real-world settings. Nutritionists and clinicians are urgently in need of guidance on whether iron supplementation may predispose children to malaria in the absence of efficacious local malaria control. This question is extremely difficult to address because nearly all trials of iron supplementation in children in high-malaria transmission areas have involved the introduction of some form of malaria control. In 1 study, for example, children were treated with iron with and without zinc and other micronutrients; they were also monitored for fever and given insecticide-treated bed nets (ITB)6 (4). Similarly, in another trial, children enrolled in the nonmalaria treatment arms with and without supplemental iron were given ITB and a dose of sulfadoxine-pyrimethamine (SP) (5). In another example of malaria surveillance, if not formal treatment, children in a study testing the effects of a micronutrient supplement were tested biweekly for fever and treated promptly (6). The Pemba trial itself included a substudy with more intense treatment and surveillance measures; in this substudy, iron supplementation did not appear to increase malaria risk over all subjects (3). Both Cochrane reviews draw on trials in which treatment and preventive measures are provided when they conclude that iron overall does not increase malaria risk.
Furthermore, as Daniel Roth and Robert Black highlighted in their commentary (7), the applicability of the Cochrane review’s findings to high-transmission areas with poor treatment and prevention availability is further reduced by the inclusion of trials in areas with less than intense malaria transmission (7, 8). The very few trials in high-malaria transmission settings that have provided iron supplementation to children without concomitant measures to combat malarial transmission, most predominantly the Pemba trial, have shown an increase in malaria susceptibility, as mentioned in the revised review (2, 3). In other trials, prompt treatment for and preventive measures against malaria, although ethically necessary, may have obscured an iron-related increase in malaria susceptibility or severity.
There is also considerable debate about whether iron supplementation should be restricted to iron-deficient or anemic patients. In the Pemba trial substudy, subjects who were anemic or iron deficient at baseline (defined by hemoglobin or zinc protoporphyrin level, respectively) actually exhibited a significant decrease in adverse events when supplemented with iron and folic acid (3). The updated Cochrane review, which defined anemia by hemoglobin level, noted that “the only variable significantly affecting this benefit [increased hemoglobin level and anemia reduction in response to iron supplementation] was baseline anemia, with anemic children gaining more than those who were nonanemic at baseline” (2). However, 1 recent trial by Veenemans et al. (9), which defined iron deficiency by ferritin concentration, found that iron-deficient subjects exhibited a significant increase in adverse events in response to supplementation with a multinutrient that contained iron. Further studies using clear and predefined measures of anemia and/or iron deficiency are required to reconcile these apparently disparate results.
In addition to modulating malaria risk in children, a growing body of evidence indicates that iron status in pregnant women has a similar effect (reviewed in reference 10). Kabyemela et al. (11) found that in primigravidae and secundigravidae, but not multigravidae, iron deficiency was associated with a significantly reduced risk of placental malaria. Senga et al. (12) found that iron-replete subjects were significantly more likely to exhibit placental malaria across all gravidity categories at time of delivery. At the time of writing this article, 2 studies are under way to compare iron-supplemented women’s risk of placental malaria with that of women who have not taken iron supplements (13, 14). These 2 studies may confirm whether maternal iron supplementation enhances the risk of placental infections, as seen in earlier studies (reviewed in reference 10).
Finally, iron availability may also modulate susceptibility to nonmalarious infectious diseases. A full analysis of these data is beyond the scope of this review, but we note several examples. An early study on supplementing iron-deficient Somali nomads with iron found that the newly iron-replete group experienced recurrences or exacerbations of various infections, including malaria, brucellosis, and schistosomiasis (15). In addition, Gangaidzo et al. (16) noted that African patients with pulmonary tuberculosis tended to have had higher levels of iron in their diets than did age-, sex-, and region-matched controls. The revised Cochrane review did not find an increased risk of nonmalaria infectious disease associated with iron supplementation, but, as the authors state, “definitions and reporting methods were highly variable” (2). This remains an issue for potential future study.
Taken together, these data indicate that iron supplementation of a susceptible host will, in the absence of effective malaria surveillance, prevention, and treatment, contribute to the likelihood of malarial infection.
Preventing infection with Plasmodium falciparum can ameliorate the problem of anemia in susceptible populations. To protect communities in general and vulnerable individuals in particular, various techniques are used. Preventing mosquito bites is 1 approach, as shown by the increasing use of ITB (17). Chemoprophylaxis is regularly used to protect naïve travelers in malaria-endemic areas, and, more recently, intermittent preventive treatment (IPT) of children and pregnant women living in malaria-endemic areas has become increasingly popular as a means of protecting those particularly at-risk groups. IPT is performed by administering antimalarial drug treatments at set intervals without first testing an individual for malarial infection (for a review, see reference 18).
Malaria treatment and prevention measures in the absence of iron supplementation have been shown to improve hemoglobin levels in multiple trials in children (19–24). Table 1 is a summary of studies that provided preventive measures against malaria infection in the absence of iron supplementation, examining the effect on anemia as approximated by hemoglobin levels. Any study subgroups in which iron supplementation was provided were excluded. The study performed by Leenstra et al. (22) is listed twice because they subdivided their study into 2 different age groups of subjects. A meta-analysis of 6 independent trials of IPT in infants (n = 7930) in 6 malaria-endemic African countries found that IPT with SP significantly decreased the likelihood of anemia developing in infants, as defined either as a packed-cell volume <25% or hemoglobin <80 g/L, depending on the trial (25). However, the protective effect of IPT on anemia development was not significant in other trials (26). Furthermore, another trial only showed an effect in younger children from use of ITB (22).
Effects of malaria treatment and prevention measures on hemoglobin levels in children1
IPT, intermittent preventive treatment; ITB, insecticide-treated bed nets; SP, sulfadoxine-pyrimethamine.
However, of the trials summarized in Table 1, only 3 addressed the effects of preventive measures against malaria in children older than the age of 4 y. One trial examining older children found no increase in hemoglobin (26), and another (22) found that hemoglobin levels in treated individuals were only significantly increased in subjects aged 12 to 13 y but not 14 to 18 y. Conversely, only 1 study that examined the effects of IPT on children younger than 4 y failed to find a beneficial effect on hemoglobin levels (27). Another study (not shown in Table 1) found IPT in children younger than the age of 1 y did not change anemia as measured by packed cell volume, but did reduce hospital admissions for anemia (28). Taking these data together, we infer that preventive treatment against malaria reduces the likelihood of anemia in younger and less immune children, but may not have a similar benefit in older children, in whom partial immunity has already developed.
The development of maternal anemia is similarly associated with peripheral (29) and possibly placental malarial infections (reviewed in reference 10). IPT with SP against malaria was shown to provide partial protection against anemia in primigravidae in a large study, as measured by hemoglobin (29). Several studies have found a significant association between anemia and peripheral parasitemia in pregnant mothers, although some (30) only observe this effect in primigravidae and some find a consistent association across gravidity categories (31). Another recent study found an association between lowered packed cell volume and peripheral parasitemia in women with asymptomatic parasitemia (32).
In 1 large study (842 enrolled women), primigravidae at 14 and 24 wk of gestation with placental malaria were shown to have significantly lowered hemoglobin levels compared with primigravidae without parasitemia (33). One smaller study of 69 primigravidae with samples collected at the time of parturition did not find an association between hematological or iron-related measurements and the likelihood of placental malaria (34); however these indices may have been physiologically altered by the intense demands of birth. Finally, placental malaria at delivery is associated with iron deficiency anemia in infants at 4 and 6 mo of age (35). Thus, maternal parasitemia is linked to an increased likelihood of maternal anemia, and placental parasitemia may also affect the iron status of the infant after birth. Prenatal chemoprophylaxis or other malaria-prevention efforts could help to prevent anemia in both mothers and infants.
Finally, host genotypes in genes related to iron control may modulate the complex interaction between malarial infection and anemia. In 2 recent studies, anemia in children was shown to increase over the malaria season, in a manner partially dependent on host genotypes (36, 37). Specifically, polymorphisms in the promoter region of TNF-α and the haptoglobin 2-2 genotype were both shown to be associated with the probability that anemia would develop in children after the malaria season (36, 37). The contributions of host genotype to iron status and malaria risk are a potentially fruitful field of research.
One possible mechanism behind the apparent long-term contribution of malaria to anemia is that parasitemia decreases the efficacy of iron supplementation. A review by Gera et al. (38) concluded that iron supplementation in hyperendemic areas was considerably less effective at increasing hemoglobin levels than in nonmalarious areas under similar conditions. In addition, the original version of the Cochrane review indicated that the beneficial effect of iron supplementation in reducing anemia in children was increased by coadministration of antimalarial drugs, although this result did not reach significance (1). The updated review stated that iron supplementation in conjunction with antimalarial treatment was effective in both preventing malaria and decreasing anemia, although no specific comparison was made between iron supplementation only and iron supplementation plus antimalarial treatment (2).
The beneficial effect of iron supplementation in conjunction with IPT is also evident in pregnant women. In a survey of >100,000 women in 18 malaria-endemic countries, Titaley et al. (39) found that self-reported iron and folic consumption in conjunction with IPT for malaria reduced the likelihood of neonatal death by 24%, but, interestingly, neither intervention was effective alone.
Only recently have researchers begun to postulate mechanistic explanations for this phenomenon. Two studies of iron incorporation during or immediately after parasitemia have been performed, both of which indicate a decrease in oral iron uptake rates in parasitemic subjects (40, 41). Doherty et al. (40) concluded that iron supplement uptake and red blood cell (RBC) iron incorporation were significantly impaired in children with malaria-induced anemia. This effect waned and lost significance by day 15 after conclusion of antimalarial treatment (40).
This finding was confirmed and expanded on by Cercamondi et al. (41) who examined the incorporation of both oral and parenteral labeled iron supplements in young nonpregnant Beninese women with asymptomatic parasitemia. Researchers administered 57Fe-labeled iron orally and 58Fe-labeled iron intravenously during asymptomatic parasitemia, then measured labeled iron incorporation into RBC 14 d after iron administration. They then repeated the process of parenteral and oral iron administration and subsequent RBC analysis 10 d after malaria treatment. This study found that asymptomatic parasitemia significantly decreased systemic use of orally administered iron, but not intravenous iron (41). A study examining iron absorption in pregnant women with postmalarial anemia vs. those with nonmalarial anemia would be of great interest. Iron incorporation under conditions of infection is less well characterized in this vulnerable population.
Hepcidin, first described just over a decade ago, is the only known human iron control hormone and the primary controller of iron uptake and recycling (42, 43) (Fig. 1). Hepcidin serves to maintain iron homeostasis by decreasing the amount of biologically available iron (44, 45). Elegant studies by Nemeth et al. (46) revealed that hepcidin acts by binding to the only known iron export protein, ferroportin, causing its internalization and degradation. Iron is absorbed from the diet by transportation into duodenal enterocytes and is then exported from enterocytes via ferroportin (47–49). Ferroportin is also expressed on the surfaces of macrophages and is responsible for exporting the iron recycled during macrophage phagocytosis of RBC (47). The effect of hepcidin is therefore to simultaneously block iron absorption from the diet and prevent iron recycling from senescent RBC. When hepcidin levels are high, the physiological effect is a restriction of iron availability to the erythron; when hepcidin levels are low, iron is absorbed successfully from the diet and recycled efficiently via macrophages.
The role of hepcidin in iron metabolism. One milligram of iron is taken in daily from the diet; most of it is loaded onto transferrin in the plasma. Much of this iron is used for erythropoiesis. Aged red blood cells are phagocytized by macrophages, which then recycle their iron back onto transferrin. Iron export from both the duodenum and macrophages is dependent on ferroportin. Hepcidin causes ferroportin’s internalization and degradation, effectively blocking iron intake from the diet and restricting iron in the body to macrophages. Image adapted from Reference (75) with permission.
Hepcidin is homeostatically up-regulated in high iron conditions (50, 51), but is also up-regulated in response to inflammatory insults (46). Hepcidin levels have been shown to be up-regulated in subjects naturally infected with malaria (52) and in experimental human infections (41, 53, 54) with hepcidin up-regulation corresponding to lowered iron status in both P. falciparum and Plasmodium vivax (55). Hepcidin levels decrease when parasitemia is treated (41). In multivariate analysis, hepcidin levels have been shown to be the most predictive index for erythrocyte iron incorporation after oral supplementation (56).
During pregnancy, rodent models have shown a steady and pronounced decrease in hepcidin during gestation as the mothers’ bodies accommodate the increased need for iron (57). One recent study specifically examining hepcidin in pregnant women found no change in maternal hepcidin between women with and without placental malaria, a result that may indicate that placental parasitemia does not affect systemic hepcidin as does peripheral parasitemia (34). However, the sample size of this study was small, and, as stated previously, samples were taken at the time of parturition. It is possible that inflammatory signals due to placental malaria were overridden by the iron perturbations that would be expected to accompany birth. In addition, whole genome expression profiling of malaria-infected placentas found that hepcidin message levels were elevated (58). In this study, increased placental hepcidin transcription correlated with decreased birth weight (58). Hepcidin-mediated iron status alteration in pregnant women, with or without parasitemia, may be a fascinating but relatively unexplored area for future studies.
The iron absorption experiments of Doherty et al. (40) and Cercamondi et al. (41) are both consistent with hepcidin-modulated prevention of iron absorption. In the former study, although children with postmalaria anemia showed initially less incorporation of oral iron compared with anemic nonmalarial controls, subjects with postmalarial anemia exhibited a significantly greater hemoglobin response at days 15 and 30 (40). Similarly, subjects recovering from postmalaria anemia showed a more rapid decrease in circulating levels of erythropoietin and a greater reduction in soluble transferrin receptor levels by day 30 (40). These data are consistent with rapid iron release from intracellular stores as hepcidin levels decrease and iron is once again exported from macrophages. In multivariate analysis of various hematological and inflammatory indices, the most consistent predictor of erythrocyte incorporation of iron after oral supplementation was hepcidin (56). In the study of Cercamondi et al. (41), oral iron failed to be incorporated into RBC, but intravenously administered iron, which circumvents the ferroportin-mediated export step from duodenal enterocytes, was similarly used by patients before and after treatment for asymptomatic parasitemia.
How hepcidin is induced during malarial infections is not yet known. One study (59) showed increased hepcidin message levels in peripheral blood mononuclear cells from healthy individuals after exposure to P. falciparum trophozoites and schizonts, but the mechanism behind this up-regulation was not identified. Hepcidin’s up-regulation is complex: it is homeostatically induced in high iron conditions via 1 pathway that appears to be at least partly dependent on bone morphogenetic protein signaling and the common-mediator second messenger SMAD protein. Hepcidin is also known to be induced by infections and inflammation. Hepcidin levels have been shown to be up-regulated during bacterial infections by Toll-like receptor agonists such as lipopolysaccharide and flagellin, through a pathway relying on the second-messenger IL-6 and the transcription factor signal transducer 3 (STAT3), which binds to a well-studied site at the hepcidin promoter (60).
New pathways for hepcidin regulation are currently under study. Liao et al. (61) have shown that nuclear factor-κB may increase hepcidin levels in response to Toll-like receptor agonists. A parallel pathway for homeostatic regulation of hepcidin appears to be dependent on phosphorylation of the intracellular protein extracellular signal-related kinase 1/2 (62, 63). Other recently discovered pathways of hepcidin induction include the unfolded protein response, triggered by endoplasmic reticulum stress (64).
Based on the link between iron and malaria, populations at risk of malaria may have been under selection pressure in genes that control iron metabolism. One possible example is TNF-α, which exhibits polymorphisms in African populations at high risk of malaria, as mentioned previously. TNF-α polymorphisms have been found to be predictive of anemia after but not before the malaria season (37). Some evidence shows that TNF-α directly inhibits iron import from the small intestine (65).
Nearly all life forms require iron for vital cellular functions. Restriction of iron, for example, by hepcidin up-regulation, may therefore represent a defense mechanism against invading pathogens. Iron chelation, which functionally mimics the reduction in bioavailable iron caused by hepcidin, has been shown in multiple studies to inhibit P. falciparum growth in vitro and in vivo (66).
How exactly reduction in bioavailable iron inhibits the growth of malaria parasites is still under discussion. Portugal et al. (67) found that liver-stage infections are inhibited by low iron availability in the host and that hepcidin alone might be responsible for this effect. Hepcidin decreases the amount of iron present in hepatocytes, which inhibits liver stage parasite development. Furthermore, these authors also found that hepcidin induced by 1 blood-stage infection can prevent the development of a second liver stage infection from a subsequent inoculation. Portugal et al. (67) suggest that this effect may decrease the chance of superinfection in naïve subjects, explaining the paucity of different parasite genotypes found in very young children who have yet to acquire immunity to infection.
Iron restriction has also been shown to inhibit the growth of parasites in blood-stage infection. However, there is currently some uncertainty about whether this effect is caused by a direct lack of iron availability to the parasites or whether this effect is immune mediated. One theory is enhanced clearance of parasitized erythrocytes in iron-deficient subjects. A recent study by Matsuzaki-Moriya et al. (68) demonstrated that although parasites in erythrocytes from iron-deficient mice continued to grow and reinvade at normal levels, macrophages cleared parasitized erythrocytes from iron-deficient mice more efficiently. Therefore, RBC synthesized under conditions of low iron availability may, when parasitized, be more efficiently identified and/or destroyed by macrophages; alternatively, macrophage function may be improved under conditions of low iron availability.
Several researchers have focused on the role of iron restriction in up-regulating nitric oxide, a small molecule that has been shown to have an antiparasitic effect (69). Weiss et al. (70) investigated the effect of the iron chelator desferroxamine (DFO) on nitric oxide production in children with cerebral malaria. They found that children treated with DFO had significantly higher levels of nitrite and nitrate, stable endproducts of nitric oxide metabolism (70). Similarly, Fritsche et al. (71) stimulated human and murine cell lines with inflammatory cytokines and found that the addition of DFO enhanced nitric oxide formation and also increased the death rate of parasites cocultured with the stimulated cells.
Other groups have investigated the role of additional cytokines. For example, Nyakeriga et al. (72) examined cytokine levels in a small cohort of iron-replete and iron-deficient children (defined by transferrin saturation and ferritin levels) in a malaria-endemic area. They found that messenger RNA levels of certain cytokines were up-regulated in peripheral blood mononuclear cells from iron-deficient but not iron-replete children (72). In general, the mechanism responsible for decreased blood-stage parasite replication or survival in iron-restricted hosts still requires elucidation, but available evidence indicates that a reduction in bioavailable host iron inhibits malaria growth during both blood and liver stage development.
The interplay between malaria and iron metabolism is complex. Iron supplementation appears to increase individuals’ susceptibility to malaria infection in vulnerable populations, which lack sufficient malaria surveillance, prevention, and treatment facilities (2). On the other hand, malaria infections cause anemia, and reduced iron absorption can contribute to this. Hepcidin, as the master controller of iron metabolism, likely contributes both to control of the basal iron levels that may predispose individuals to malarial infection and separately to anemia during malaria infections.
Nutritionists deliberating whether to supplement children and/or pregnant women in malarious areas with iron should take into account the potential increase in malaria risk incurred by iron supplementation in subjects without access to adequate malaria protection and treatment. As stated in the revised Cochrane review, treatment and protection measures are in general improving in sub-Saharan Africa, thus presumably making iron supplementation much safer (2). However, the WHO 2011 Malaria Report, although highlighting progress made in malaria control, also notes that malaria may be increasing in a minority of countries and highlights the fragility of the advances made (73). Further, novel modeling techniques (74) suggest, albeit controversially, that malaria was the likely cause of death of 1.24 million individuals in 2010, a startling upward estimate that underscores the continuing burden of malaria. Taking all available evidence into account, it may be premature to conclude that iron supplementation is safe enough to implement in an area without consideration of malaria control and treatment facilities.
As a separate issue, iron supplementation of malarious populations may be less effective than in other populations, owing to their higher hepcidin levels. Individuals with higher hepcidin do not incorporate oral iron into RBC as well (56). Therefore, a test that reliably and inexpensively estimates circulating levels of hepcidin peptide in patient serum or urine might prove extremely useful in ascertaining whether the anemia in that particular patient is due to infection or lack of dietary iron. High levels of hepcidin would indicate anemia that is likely to be oral iron refractory but responsive to treatment with antiparasitics or antibiotics, whereas low hepcidin would indicate anemia due to genuinely low physiological iron stores, a condition that would respond to oral iron therapy. These tests may be confounded by various factors that are beyond the scope of this paper but commonly occur in malaria-endemic settings, particularly vitamin A deficiency, gut parasites such as helminths, and various hemoglobinopathies. Despite these pitfalls, hepcidin is a key measure of iron regulation and may be especially useful in distinguishing inflammation and iron deficiency as the root cause of anemia. Anemia and malaria remain serious problems and often co-occur. Further research into understanding the interplay between the 2 will help us to address both problems.

Surrogates are just surrogates, but helpful just the same


A surrogate end-point biomarker (SEB) may broadly be defined as a predictive measure of a future outcome. For individuals without evidence of cancer, a risk biomarker predicts clinical disease onset. In the case of established cancer, a risk biomarker predicts recurrence or progression. A response biomarker is usually a reversible risk biomarker that predicts disease prevention or, in the case of established cancer, eradication or temporary control.
To be credible, an SEB must have biological plausibility and a strong association with ultimate outcome. To be used for prevention, an SEB should be identified as being causally related to the development of precancer and cancer. Modulation of the SEB through an intervention should predict outcome. The SEB should be reproducible and reliable. Reproducibility is generally maximized with a quantitative biomarker. Optimally, both risk and response SEBs should be prospectively validated in a clinical trial in which the nonsurrogate outcome is also being evaluated [1,2].
SEBs are used in clinical trials to identify effective new strategies faster and more economically with fewer patients. They may also offer insight into why or why not a particular therapy does not work. In the patient care setting, SEBs are used to determine whether and when to change the therapeutic plan.
In the metastatic setting, typically the same surrogate markers are measured repeatedly to assess response or progression often by imaging and/or physical examination. Two surrogate markers can independently predict the same outcome, but results at any single point in time may be discordant. Consequently, it is important to understand the biology that underlies the surrogate in order to avoid making inappropriate clinical decisions.
In the neoadjuvant setting, a low Ki-67 a few weeks after initiation of treatment and pathological response after several months of treatment both predict long-term disease-free survival [3-5]. Both biomarkers are currently used in the research setting, and pathological stage after neoadjuvant treatment is used clinically to estimate distant disease-free survival. It is probable that, in the near future, early reduction in breast proliferation will be used along with clinical indices to determine whether to switch antihormonal or chemotherapeutic treatment during the neoadjuvant period. Pathological response after neoadjuvant chemotherapy will also probably be used to determine whether to administer additional chemotherapy adjuvantly to women with hormone receptor negative tumours (Figure 1).
Surrogate response biomarkers will guide neoadjuvant treatment. ER, oestrogen receptor; pCR, pathological complete response; PR, progesterone receptor; Rx, treatment.
Perhaps the greatest need for surrogate biomarkers is in the prevention setting, where the traditionally measured outcome of cancer occurs infrequently and only after a long latent period. Biomarkers that accurately predict short-term risk are needed in order to avoid treating healthy women with drugs tthat most do not need in order to benefit a few. Reversible risk biomarkers could be used to monitor response for those individuals undergoing the intervention.
Serum levels of insulin-like growth factor (IGF)-1, the ratio of IGF-1 to its binding protein IGFBP-3, serum luteal phase progesterone and free testosterone in premenopausal women, and prolactin and bioavailable oestradiol and testosterone in postmenopausal women are examples of risk biomarkers that can be measured with a simple blood test [6]. However, the two biomarkers associated with the greatest relative risk for invasive cancer and likely to be most reflective of events at the level of the breast are mammographic density and intraepithelial neoplasia.
Mammographic density is reflective of the amount of stroma, epithelium and fluid in the breast relative to fat. There are both qualitative and quantitative means of measuring mammographic density [7,8]. Using the computer-assisted method of Boyd and Yaffee, women with more than 75% area of increased density have an approximate fivefold increase in risk relative to those with no increased density (that is, a completely fatty breast). Mammographic density has been shown to increase modestly the concordance statistic associated with Gail model predicted probability, and thus it should improve the accuracy of individual risk estimates [9,10]. The advantages of mammographic density as an SEB is that it is quantitative, positively associated with some risk factors (including benign breast disease, and oestrogen and progestin combined hormone replacement therapy [11,12]) and can be obtained at minimal extra cost and with no extra procedure in screened women.
The disadvantages are that it is negatively correlated with some risk factors, including age and obesity, and may be negatively correlated with free oestradiol. There is substantial technical and interpretive variance, and it is unclear whether effective agents such as tamoxifen and raloxifene reduce density in postmenopausal women over 55 years old [13-16]. Cuzick and coworkers [15] suggested that reduction in density is associated with only one-third of the risk reduction resulting from tamoxifen administration.
It is quite possible that density results from the interplay of stromal and epithelial mitogens such as IGF-1, oestrogen and progestin, such that if one or more of the factors is low at baseline and/or is unaffected by the prevention intervention, then no change may occur in density, although risk may be diminished.
The findings of hyperplasia and atypical hyperplasia in a diagnostic biopsy are associated with an approximate twofold and fivefold subsequent increase in risk for breast cancer, respectively [6]. Because most women have not had a diagnostic biopsy, another method is required to obtain tissue for risk stratification and for monitoring a prevention intervention.
Both nipple aspirate fluid (NAF) and random periareolar fine needle aspiration (RPFNA) evidence of atypia have been shown to increase the concordance statistic based on the Gail model [17-19]. NAF harvest is noninvasive and inexpensive, but the majority of NAF samples have no or few cells whereas more than 90% of RPFNA samples are cellular [17]. The advantages of breast tissue sampling by RPFNA for risk and response biomarkers is that it provides a direct assessment of precancerous change as well as tissue for other response and predictive markers such as Ki-67 and oestrogen receptor (ER), and there is minimal discomfort. Disadvantages are that it does involve a procedure that requires training, and there is both intra- and inter-observer interpretive variance.
Arzoxifene is a third-generation selective oestrogen receptor modulator (SERM) similar to raloxifene but with greater potency, primarily because of greater bioavailability. We assessed the effect of 6 months of arzoxifene compared with placebo on several risk biomarkers as part of a multi-institutional National Cancer Institute sponsored phase II prevention trial [20]. Compared with placebo, there was no change in cytomorphology index score, but there was a significant favorable modulation of mammographic breast density, breast tissue ER expression and serum IGF-1/IGFBP-3 ratio. These changes were more marked in premenopausal than in postmenopausal women. Arzoxifene is being further assessed in a phase III prevention trial with incidence of bone fracture and breast cancer as two co-primary end-points.
From the arzoxifene phase II trial we learned that change in biomarker expression may vary with menopause status and that cytomorphology change is not a sensitive indicator of SERM bioactivity after short-term administration. Expression of Ki-67 and ER increase with morphological abnormality in benign breast tissue whether sampled by diagnostic biopsy or RPFNA [21-23]. Consequently, changes in Ki-67 and ER expression were explored as end-points for phase II trials with antihormonal agents in our trial of letrozole in high-risk women on HRT. Ki-67 is also higher in premenopausal than in postmenopausal women [22]. The concept of using letrozole in high-risk women taking hormone replacement therapy (HRT) has been shown to be valid in hormonally intact aromatase over-expressing mice [24]. Postmenopausal women produce the majority of breast oestrogen locally via aromatase and sulfatase [25] and aromatase activity is increased in precancerous breast tissue [26].
We found a significant decrease in benign breast tissue Ki-67 (mean 5.1% at baseline and 1.5% after 6 months of letrozole) in 42 high-risk women on a stable dose of hormone replacement. There was no significant accompanying change in serum oestradiol, IGF-1, the IGF-1/IGFBP-3 ratio, or mammographic breast density [27]. Cytomorphology designation was likewise unchanged after 6 months of letrozole, although the proportion of abnormal cells in the specimens by karyometry was reduced from baseline [28]. Given our pilot study results, the concept of utilizing letrozole to reduce breast cancer risk in women on HRT is being tested further in a multi-institutional placebo controlled trial sponsored by the US National Cancer Institute.
Modulation of an individual surrogate response biomarker is likely to be dramatically influenced by agent, menopause status and baseline characteristics of the cohort (Table 1). Biomarkers are extremely valuable in initial testing of new strategies, particularly in prevention. However, it is important to understand how the agents may differentially modulate risk biomarkers, so that an effective agent is not discarded because it does not favourably modulate all risk biomarkers. Currently, response biomarkers for prevention are utilized only within the context of phase I and II trials. Surrogate markers in metastatic disease and in the neoadjuvant arena are helpful both for research and in clinical decision making.
Biomarker change by antihormone type and menopause
E2, oestradiol; IGF, insulin-like growth factor; HRT, hormonre replacement therapy; IGFBP, IGF-1 binding protein; NA, not applicable.

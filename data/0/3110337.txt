Large-Scale Brain Networks Underlying Language Acquisition in Early Infancy

Edited by: Judit Gervain, CNRS – Université Paris Descartes, France
Reviewed by: Richard N. Aslin, University of Rochester, USA; Mgarco Ferrari, University of L'Aquila, Italy
This article was submitted to Frontiers in Language Sciences, a specialty of Frontiers in Psychology.
A critical issue in human development is that of whether the language-related areas in the left frontal and temporal regions work as a functional network in preverbal infants. Here, we used 94-channel near-infrared spectroscopy to reveal the functional networks in the brains of sleeping 3-month-old infants with and without presenting speech sounds. During the first 3 min, we measured spontaneous brain activation (period 1). After period 1, we provided stimuli by playing Japanese sentences for 3 min (period 2). Finally, we measured brain activation for 3 min without providing the stimulus (period 3), as in period 1. We found that not only the bilateral temporal and temporoparietal regions but also the prefrontal and occipital regions showed oxygenated hemoglobin signal increases and deoxygenated hemoglobin signal decreases when speech sounds were presented to infants. By calculating time-lagged cross-correlations and coherences of oxy-Hb signals between channels, we tested the functional connectivity for the three periods. The oxy-Hb signals in neighboring channels, as well as their homologous channels in the contralateral hemisphere, showed high correlation coefficients in period 1. Similar correlations were observed in period 2; however, the number of channels showing high correlations was higher in the ipsilateral hemisphere, especially in the anterior–posterior direction. The functional connectivity in period 3 showed a close relationship between the frontal and temporal regions, which was less prominent in period 1, indicating that these regions form the functional networks and work as a hysteresis system that has memory of the previous inputs. We propose a hypothesis that the spatiotemporally large-scale brain networks, including the frontal and temporal regions, underlie speech processing in infants and they might play important roles in language acquisition during infancy.

When we listen to speech sounds of our native language, we automatically convert a train of phonological/prosodic information into meaning in our brains. We know that multiple steps lie behind this process. Although, in most cases, we do not consciously notice every step, the first step is the detection and analysis of acoustic information (Price, 2010). The acoustic information is processed in the bilateral temporal regions, and the role of each hemisphere is considered to be different. One model proposes that the left and right hemispheres are related to the processing of temporal and spectral information, respectively (Zatorre et al., 2002; Zatorre and Gandour, 2008). Another model suggests that both hemispheres have a short window in temporal integration (about 20–80 ms) and that the right hemisphere has a relatively long window (about 150–300 ms; Poeppel et al., 2008). The two models support the many studies that showed bilateral activation in speech and music perception and that reported hemispheric differences between the processes. Infant studies also reported bilateral activation in the temporal regions (Kotilahti et al., 2005) and lateralized activation (Telkemeyer et al., 2009), in which the right hemisphere showed responses to slow acoustic modulations. If, however, we assume the time window to be shorter than 300 ms, the left-lateralization in brain activation during speech processing would not be fully explained, because phonological information and word-level/sentence-level prosody are converged during word recognition and sentence comprehension over a longer time scale. The assumption of a longer time window in the brain, beyond the time span of the acoustic processing, will enable us to give a fuller picture of speech processing and sentence comprehension.
The spoken language processing progresses from acoustic analysis to detect words and construct sentences, and further evolves to understand the meaning of the sentences. These succeeding processes require longer time than acoustic and phonological processing, which takes up to several hundred milliseconds. Syntax, which is the core of a language faculty, interplays other cores of phonology and meanings (semantics). This grammatical rule system works to construct the hierarchical and recursive structures unique to the human language (Hauser et al., 2002). The processing of a hierarchically structured sequence has been shown to cause activation in the left inferior frontal region (Brodmann's area, BA; 44/45), as well as in the left frontal operculum (BA 6/FO) and the temporal regions (Friederici et al., 2006). The tractography using the diffusion tensor imaging (DTI) depicted the connection between the left BA 44/45 and the posterior and middle portion of the superior temporal region via the superior longitudinal fasciculus (Catani et al., 2002; Friederici et al., 2006). It was argued that these regions form a syntactic network, in which the function of BA 44/45 is to support the hierarchical reconstruction of the syntactic structure from the sequential input (Friederici, 2006). This network would need to function in a longer time window than several hundred milliseconds. The critical issue in both developmental and language sciences is whether the frontal and temporal regions of preverbal infants work as a functional network, which could then be considered a candidate for the neural foundation of language acquisition.
The functional architecture of the infant brain is beginning to be examined by resting-state functional connectivity magnetic resonance imaging (fcMRI; Fransson et al., 2007, 2011; Gao et al., 2009; Smyser et al., 2010). These fcMRI studies reported the putative precursors of the default-mode networks and their development. We recently found the development of global cortical networks from neonates to 3- and 6-month-old infants by using multi-channel near-infrared spectroscopy (NIRS; Homae et al., 2010): The temporal, parietal, and occipital regions show increases in homologous connectivity connecting the left and right hemispheres, and the fronto-occipital connectivity show U-shaped changes in the course of development. The resting-state measurements successfully provide information about the organization of infant brains, whereas the functional networks related to perceptual and cognitive processing are not fully examined. Supporting evidence for these networks in infants is revealed by anatomical and functional imaging studies. DTI studies on infants visualized the superior longitudinal fasciculus connecting these regions (Zhang et al., 2007; Dubois et al., 2009). Our previous studies (Homae et al., 2007; Nakano et al., 2009), Gervain et al. (2008), and Imada et al. (2006) reported co-activation in the frontal and temporal regions, suggesting that these regions collaborate to process speech sounds. Changeux and his collaborators proposed a “global neuronal workspace (GNW)” model, in which a long-distance temporofrontal GNW circuit of infants is activated by speech stimuli (Dehaene et al., 1998; Lagercrantz and Changeux, 2009). Based on these observations, we attempt to clarify the state-dependent functional networks in the infant brain specifically involved in speech processing. We expect that such a long-distance connectivity would have a longer time window and show high correlations in a lower frequency domain.
In the present study, we measured the brain activation and functional connectivity of 3-month-old infants by using 94-channel NIRS (Figures 1A,B). We prepared three periods for measurements (Figure 1C). During the first 3 min, we measured spontaneous fluctuation of activity in the brain (period 1). After period 1, we provided stimuli by playing Japanese sentences for 3 min (period 2). Finally, we measured brain activation for 3 min without providing the stimulus (period 3), as for period 1. We evaluated the changes in oxygenated and deoxygenated hemoglobin (oxy-Hb and deoxy-Hb) signals for each measurement channel. In addition, we mapped the functional connectivity in each period by calculating the time-lagged cross-correlations of oxy-Hb, deoxy-Hb, and total-Hb (summation of oxy-Hb and deoxy-Hb) signals between channels. Our primary concern was to reveal the functional networks that are activated during the presentation of speech sounds. We further examined whether the functional networks show context-dependent changes by contrasting the networks under no-stimulus conditions both before and after the presentation of speech sounds.
Experimental settings. (A,B) The NIRS probe and 94 measurement channels. Probes were placed over the bilateral frontal, temporal, temporoparietal, and occipital regions of infants. The probes and measurement channels (open circles in B) were correctly positioned utilizing the 10–20 system. (C) Three periods during the measurement. During the first 3 min, we measured spontaneous brain activation (period 1). After period 1, we provided stimuli by playing Japanese sentences; the sentences were played at 20-s intervals for 3 min (period 2). Finally, we measured brain activation for 3 min without providing the stimulus (period 3), as in period 1.
Twenty-one 3-month-old infants participated in the present study (11 girls and 10 boys; mean age: 111.6 days; range: 104–123 days). All infants were full-term healthy Japanese. They were sleeping quietly while they were studied. An additional 56 infants were studied, but they were excluded from the analysis due to either producing large head movements resulting in motion artifacts in the signals (N = 13) or probe obstruction by hair (N = 7). The measurement was stopped when infants awoke from their sleep during the experiments (N = 36). A success rate of sleeping infants was 51.2% (21/41). We checked the number of times the infants moved their heads, bodies, arms, and legs even if they were asleep. The number of movements by each infant at all periods (3 min each) was less than 2 (0: N = 10, 1: N = 7, and 2: N = 4). The total number of movements was 15 (1 × 7 + 2 × 4 = 15), and the occurrences of movements were equally distributed (five times during each period). The motion during period 2 was not concentrated to the first trial; we observed movements during the 1st, 2nd, 3rd, 5th, and 7th trials within the nine trials of period 2. This behavioral analysis suggests that the state of arousal in the infant group did not change during the three periods. The measurement was stopped when infants awoke from their sleep during the experiments. Informed consent was obtained from the parents of the infants prior to the initiation of the experiments. The study was approved by the ethics committee of the Graduate School of Education, University of Tokyo.
The speech stimuli used in the present study were a subset of normal speech sounds described previously (Homae et al., 2006, 2007). The stimuli consisted of nine Japanese sentences recorded by a female Japanese speaker (16 bit, 22050 Hz). The mean duration of the sentences was 4.0 s.
All experiments were conducted in a sound-attenuated room (the background noise: less than 30 dB SPL). The infant was held in an experimenter's arms during the measurement of cortical activation. The infants were almost motionless and slept soundly throughout the experimental sessions. We previously reported that NIRS recordings from infants in daytime sleep provide long-duration and motion-free data with a sufficiently high signal-to-noise ratio, and the obtained data can be used to evaluate cortical responses to sounds (Homae et al., 2006, 2007, in press; Taga et al., 2007; Nakano et al., 2008, 2009). Stimulus-dependent hemodynamic responses in the brain to speech sounds have been reported in fMRI studies on sleeping adults and infants (Portas et al., 2000; Dehaene-Lambertz et al., 2002), and in NIRS studies on sleeping neonates and infants (Peña et al., 2003; Homae et al., 2006, 2007).
During the first 3 min, we measured spontaneous fluctuation of activity in the brain (period 1, Figure 1C). The fluctuation of brain activation and the functional connectivity have been reported previously using this data set (Homae et al., 2010). In period 2, we presented nine different sentences, each of which lasted 4 s followed by 16 s of silence. Speech sounds were presented at a maximum amplitude of 65 dB SPL using a BOSE MMS-1 speaker system placed in front of the infant. During the inter-stimulus interval, no sound was presented. Finally, we measured the brain activation for 3 min without providing the stimulus (period 3), as for period 1.
We used multi-channel NIRS instrument (ETG-7000, Hitachi Medical Corporation, Tokyo, Japan). The NIRS instrument exploits the optical properties of hemoglobin, which has oxygenated and deoxygenated forms with different absorption spectra in the near-infrared (NIR) wavelength region. By using two NIR wavelengths (785 and 830 nm in ETG-7000) and applying the data analyses based on the modified Lambert–Beer law, these instruments measure the relative changes in the concentrations of oxy-Hb and deoxy-Hb in the cerebral cortex at preset measurement points. Detailed descriptions of the principles underlying NIRS have been previously described (Jöbsis, 1977; Reynolds et al., 1988; Maki et al., 1995; Villringer and Chance, 1997; Obrig and Villringer, 2003; Hoshi, 2007; Wolf et al., 2007; Minagawa-Kawai et al., 2008; Lloyd-Fox et al., 2010; Gervain et al., 2011). NIRS has been successfully used to investigate cortical activation in infants in response to auditory stimuli (Peña et al., 2003; Kotilahti et al., 2005, 2010; Homae et al., 2006, 2007, in press; Minagawa-Kawai et al., 2007; Taga and Asakawa, 2007; Taga et al., 2007; Nakano et al., 2008, 2009; Telkemeyer et al., 2009).
Near-infrared light was emitted from laser diodes through incident optical fibers. The maximum intensity of NIR light was set at 0.6 mW. The received light was detected by avalanche photodiodes through detection via optical fibers and separated into individual light sources, depending on each wavelength. We used two sets of 3 × 10 arrays composed of 15 incident and 15 detection fibers, which were mounted on a flexible cap over the frontal, temporal, temporoparietal, and occipital areas of each hemisphere (Figures 1A,B). Each pair of adjacent incident and detection fibers defined a single measurement channel, which enabled us to simultaneously measure the time course of oxy-Hb and deoxy-Hb signals with a 0.1-s time resolution. The distance between incident and detection fibers was set at approximately 2 cm (Taga et al., 2007). The measurement channels were correctly positioned by reference to the international 10–20 system of electrode placement using landmarks of external auditory pores, vertex, and inion from each infant. Because few available atlases exist for the infant brain, we used previous studies on adults (Homan et al., 1987; Steinmetz et al., 1989; Herwig et al., 2003; Okamoto et al., 2004) to estimate the craniocerebral correlation for each measurement channel. A recent MRI study suggested that the cortical structure in infants is similar to adults in many aspects (Hill et al., 2010). We have reported functional mapping for audio–visual stimuli in infants, which is consistent with an estimated map from the craniocerebral correlation (Watanabe et al., 2008, 2010).
We examined the variation in the oxy-Hb signals, which estimated changes in the regional cerebral blood oxygenation during brain activation. In addition, we also analyzed the deoxy-Hb signals. We evaluated relative changes in oxy-Hb and deoxy-Hb signals contingent on an arbitrarily assigned 0 baseline from the start of the measurement period, which was based on the modified Lambert–Beer law. Because the precise optical path length of the light traveling through brain tissue cannot be evaluated by continuous-wave NIRS, the units of oxy-Hb and deoxy-Hb signals were determined by multiplying the molar concentration by length (mM·mm).
For each individual data set, we used a band-pass filter from 0.009 to 0.08 Hz, which has been used in previous studies on adult participants to eliminate cardiac and respiratory rhythms (Fox et al., 2005; White et al., 2009), and extracted 3-min data (i.e., 1,800 time points) from the continuous time courses (periods 1, 2, and 3). The band-pass filter eliminated cardiac pulsation (about 2 Hz in infants) and smoothed signal drifts over long time scales and motion artifacts.
We initially extracted data blocks from the time course data of period 2. Each data block ranged from 0.5 s prior to stimulus onset to 19.5 s after stimulus onset. By detecting rapid changes in the summation of oxy-Hb and deoxy-Hb signals before applying the band-pass filter, we determined data blocks to be eliminated with a low signal-to-noise ratio due to obstruction by hair and those with movement artifacts. We then calculated the mean signal of the first 11 time points (i.e., from 0.5 s prior to stimulus onset, during which no sounds was presented, to 0.5 s after stimulus onset) in each data block and used this value as the baseline for each block. By averaging the signal changes over data blocks for each subject in period 2, we obtained the hemodynamic responses at each measurement channel. To identify the activated regions in the period 2, we evaluated the individual data as random effects and performed a t-test, which was performed against 0 baseline (one-sample, two-tailed t-test), for each channel. Multiple comparisons among the measurement channels were considered by adopting an all-measurement-channels false discovery rate (FDR) correction at Q < 0.05 (Benjamini and Hochberg, 1995; Genovese et al., 2002; Singh and Dan, 2006).
For each infant data of oxy-Hb, deoxy-Hb, and total-Hb (summation of oxy-Hb and deoxy-Hb) signals, we calculated the time-lagged correlation coefficients (r) between the time course of a single channel and the time course from all other measurement channels (number of pairs: (94 × 93)/2 = 4,371). The 3-min data of two channels determined a single r value. We settled 20-s time window (±10 s) for lags, and calculated correlation sequences over the lag range (from −10 to 10 s). Because sampling rate was 10 Hz, we obtained 201 r values for each pair as a sequence. We adopted the maximum r value among the 201 values as the r value for the pair. In most cases, we used r values within 2-s lags in the present analysis (mean values of lags in oxy-Hb signals: −0.034, −0.150, and 0.124 s in periods 1, 2, and 3, respectively; mode values of lags in oxy-Hb signals: 0.0 s in all periods). We used all the filtered data to estimate the cross-correlations. Because we used correlation coefficients in our analyses, the different optical path lengths of the measurement channels did not affect our results. We considered both positive and negative r values (range: –1 ≤ r ≤ 1) and evaluated all the r values. To reveal the changes in connectivity between the periods, we analyzed the differences on a channel pair basis. We first converted the r values to z scores by Fischer's z transformation. We evaluated the individual z scores as random effects and performed paired t-tests (statistical threshold: p < 0.005). We applied two types of the comparison: (1) period 1 and period 2 and (2) period 1 and period 3. We recently found that the patterns of frequency-specific functional connectivity are different between oxy-Hb and deoxy-Hb signals (Sasai et al., 2011). Further, Mesquita et al. (2010) calculated resting-state functional connectivity using oxy-Hb, deoxy-Hb, and total-Hb signals. They reported a trend toward a higher correlation between homologous regions in total-Hb signals in comparison to oxy-Hb and deoxy-Hb signals; however, one cannot exclude qualitative and quantitative differences among the signals. Because oxy-Hb signals displayed a better signal-to-noise ratio than deoxy-Hb signals in our previous study (Homae et al., 2007), we focused on oxy-Hb signal changes to make direct comparisons between periods.
We further calculated the squared coherence of oxy-Hb signals between channel pairs. In this analysis, we used raw data without any filters. We applied Welch's averaged, modified periodogram method (using a 1024 point Fourier transform, Hanning window, and overlap of 512 points) to estimate the cross spectral density and the power spectral density. The magnitudes of squared coherence were calculated from them. The values for each frequency were averaged in each infant.
In the cluster analyses for oxy-Hb, deoxy-Hb, and total-Hb signals, we defined the distance between the two channels by calculating 1 – r. We applied the Ward method for determining the distance and constructed a dendrogram. We showed four clusters for each period.
We found that 3-month-old infants showed spontaneous brain activity and hemodynamic responses to speech sounds in both the left and right hemispheres (Figure 2). The temporal, temporoparietal, and occipital regions showed remarkable signal changes from the baseline during period 2 (around the onset of the stimulus presentation, see Materials and Methods). These regions showed increases in oxy-Hb signals as well as decreases in deoxy-Hb signals. Moreover, the oxy-Hb signal changes were larger than the deoxy-Hb signal changes. To quantify the hemodynamic responses to speech sounds, we created an average time course of all the measurement channels in period 2 (Figure 3). The maximum change in the oxy-Hb and deoxy-Hb signals occurred at 8.8 and 10.6 s, respectively. For the statistical analyses using t-tests, we used the mean changes of the oxy-Hb signals in the time window from 6.9 to 10.7 s, and the deoxy-Hb signals in the time window from 8.9 to 12.2 s after the onset of the stimulus presentation, in which the signal changes were greater than 2 SDs for all time points of the averaged time course of oxy-Hb and deoxy-Hb signals.
Representative signal changes in the three periods. The oxy-Hb and deoxy-Hb signal changes in five channels in each hemisphere were plotted. The red and blue lines indicate oxy- and deoxy-Hb signals, respectively. The vertical lines in period 2 indicate the onset and offset of the stimulus presentation.
The averaged time courses of oxy-Hb and deoxy-Hb signal changes in all the measurement channels during period 2. The gray bar indicates the period during which the speech sounds were presented (mean duration: 4.0 s). The red and blue lines indicate oxy-Hb and deoxy-Hb signals, respectively.
By conducting statistical analyses of the mean changes in oxy-Hb signals, we examined cortical activation in response to the speech sounds (period 2). We found that the bilateral prefrontal, temporal, and temporoparietal regions of the 3-month-old infants showed significant activation (Figure 4). The activation patterns in the bilateral regions of infants were consistent with our previous results using speech sounds (Homae et al., 2006; Taga and Asakawa, 2007; Nakano et al., 2008, 2009). We further found significant signal changes in the bilateral occipital regions. These bilateral changes were also observed in deoxy-Hb signals. The increase in oxy-Hb signals and the decrease in deoxy-Hb signals in the occipital regions indicated that these regions of 3-month-old infants were activated when speech sounds were presented to the infants. We calculated the time of maximal changes in oxy-Hb and deoxy-Hb signals. The timings in the oxy-Hb signals in the temporal channels of the left and right hemispheres were 8.5 and 8.8 s, respectively (Figure 5A). The timings in the oxy-Hb signals in the occipital channels of the left and right hemispheres were 9.4 and 9.1 s, respectively (Figure 5B). The timing of deoxy-Hb signal in the temporal channels of both the left and right hemispheres was 8.5 s (Figure 5C), whereas in the occipital channels of the left and right hemispheres, the timings were 10.8 and 10.9 s, respectively (Figure 5D). The rates of increases or decreases during the first 5 s were also different between the temporal and occipital regions. The difference between the regions were not specific to the above four channels (see the inset in Figure 5). We calculated the mean peak time in oxy-Hb signals in each column from temporal regions to the occipital regions (10 columns in total). The mean timing in the temporal channels (three channels in each hemisphere, column 1), and in the occipital channels (two channels in each hemisphere, column 10) was 8.47 and 9.20 s, respectively (Figure 5E). These analyses demonstrate that the temporal profiles of signal changes were region specific. Based on these findings, we suggest that the activation seen in the extensive cortical regions are not global systemic effects, but reflect region-specific cortical activation.
The signal changes in all measurement channels during period 2. (A) The averaged time courses. The red and blue lines indicate oxy-Hb and deoxy-Hb signals, respectively. The 0 baseline was set at the mean value elicited for each measurement channel around the stimulus onset (see Materials and Methods). (B) The statistical map of the oxy-Hb signal increases and deoxy-Hb signal decreases in period 2. The red filled circles indicate measurement channels that showed significant oxy-Hb signal changes (p < 0.05, FDR corrected). The blue open circles over the red circles indicate measurement channels that showed deoxy-Hb signal changes (p < 0.05, FDR corrected).
The signal changes in the temporal and occipital channels during period 2. (A) The average time course of oxy-Hb signals in the left hemisphere. The red and magenta lines indicate the temporal and occipital channels, respectively (filled circles in the bottom panel). (B) The average time course of oxy-Hb signals in the right hemisphere. The red and magenta lines indicate the temporal and occipital channels, respectively. (C) The average time course of deoxy-Hb signals in the left hemisphere. The blue and cyan lines indicate the temporal and occipital channels, respectively (filled circles in the bottom panel). (D) The average time course of deoxy-Hb signals in the right hemisphere. The blue and cyan lines indicate the temporal and occipital channels, respectively. (E) The average peak time of the oxy-Hb signals in 10 columns from temporal to occipital columns. The abscissa indicates the columns shown in the bottom panel. The average time courses were calculated from oxy-Hb signals of 6 channels (columns 1, 3, 5, 7, and 9 in the left and right hemispheres; three channels in each hemisphere) or four channels (columns 2, 4, 6, 8, and 10 in the left and right hemispheres; two channels in each hemisphere), and the peak time in each time course was investigated. The ordinate shows the peak time from the onset of the stimulus presentation.
To test whether the signal changes in the left and right hemispheres showed differences, we applied direct comparisons between the signal changes in homologous channels (47 pairs). These comparisons were based on the assumption that the optical path lengths in homologous regions were equivalent to each other. No regions showed significant differences between the homologous channels. This result demonstrated that both hemispheres were involved in the processing of speech sounds.
Next, we calculated temporal correlations between all the pairs of measurement channels during each period (r > 0.5, Figures 6 and 7). In period 1, during which no stimuli were presented, the prominent connectivity caused by the spontaneous brain activation was observed in homologous channels, as reported in our previous study (Homae et al., 2010). When speech sounds were presented (period 2), the number of channel pairs that exhibited high correlations increased throughout the brain. Not only the homologous connectivity, but also fronto-posterior connectivity in the ipsilateral hemisphere appeared. After the stimulus presentation (period 3), we found that the fronto-posterior connectivity in the ipsilateral hemisphere still showed high correlations. This tendency remained even if we calculated correlations using the last 150-s data. In the following analyses, we focused on two direct comparisons of these correlations: period 1 vs. period 2, and period 1 vs. period 3. The former comparison will clarify cortical networks related to the processing of speech sounds. The latter will reveal the aftereffects of the perceiving of speech sounds. If the processing occurs only in the midst of speech-stimulus presentation, we will obtain null results in the latter comparison; otherwise, the functional networks will show state-dependent changes.
Functional networks based on oxy-Hb signals, deoxy-Hb signals, and total-Hb signals. (A) Temporal correlations in oxy-Hb signals across the three periods. The distributions of correlation coefficients (r values) are shown by the three lines. The ordinates denote the total number of channel pairs across the infants. The representative correlations during each period are exhibited. The five channels in each hemisphere are the same as those shown in Figure 2. The lines show correlations that are higher than 0.5 (averaged across all infants in each group). (B) Temporal correlations in deoxy-Hb signals. (C) Temporal correlations in total-Hb signals.
All the connectivity in the three periods. The lines show correlations that were higher than 0.5 (averaged across all infants). The correlations between one of the 94 measurement channels and other channels are shown according to the arrangement of channel settings (Figure 1B).
The direct comparison between period 1 and period 2 revealed the increases in connectivity in period 2 (Figure 8A). Both the homologous connectivity and fronto-posterior connectivity in period 2 was higher than those in period 1. The higher fronto-posterior connectivity in the ipsilateral hemisphere was found in the left and the right hemispheres (Figure 8B). The most prominent changes were observed in prefrontal and posterior temporal/occipital connectivity in the right hemisphere (p = 0.0001, a bold line in Figure 8B), and the left homologous connectivity also showed large changes (Figure 8C). When we ceased to present speech sounds (period 3), correlations between these regions returned to the level of period 1, suggesting that these networks functioned during the processing of speech sounds.
The direct comparison between period 1 and period 2. (A) All the connectivity that showed higher correlations in period 2 in comparison with period 1 (p < 0.005). (B) The ipsilateral connectivity revealed by the direct comparison (p < 0.005). The bold line indicates the connectivity that showed the largest difference. The thick circles show the measurement channels of a right temporoparietal region and a right prefrontal region. (C) Individual data of temporal correlations normalized to z scores. The scatter plots show z scores in the pair indicated by the bold line in (B) and its left homologous pair. The blue, red, and green circles indicate individual data of z scores during periods 1, 2, and 3, respectively. The black circles indicate mean values in each period.
In addition, hemispheric differences were observed in this comparison. For one example, correlations between the anterior regions of the prefrontal cortex and the occipital regions in the left hemisphere were higher than those in the right hemisphere. Another example is that the right temporoparietal region, which is related to the processing of pitch information (Homae et al., 2006, 2007, in press), showed an increase in connectivity with the right prefrontal region (thick circles in Figure 8B), whereas the left homologous pair did not exhibit such changes (p > 0.1). These differences were not clarified when the intensity of signal changes was tested. The analyses of functional connectivity provided novel information about the processing of speech sounds in the infant brain.
Both periods 1 and 3 were no-stimulus conditions, but the context of period 3 differed from that of period 1. If the presentation of speech sounds affects the brain networks for a long time, functional connectivity in period 3 would be expected to differ from that of period 1. The direct comparison between the two periods supported this possibility. We found that the fronto-posterior connectivity between the prefrontal regions and the temporal/temporoparietal regions in period 3 are higher than those in period 1 (Figure 9A). We used all four pairs in each hemisphere, which connect the frontal and posterior regions (bold lines in Figure 9A), to calculate mean z values for each subject (Figure 9B). The mean r values of the four pairs in period 3 were 0.572, 0.557, 0.554, and 0.523 in the left hemisphere and 0.472, 0.462, 0.458, and 0.447 in the right hemisphere. We confirmed that the differences between period 1 and period 3 were significant (both hemispheres: p < 0.0005), indicating that the presentation of speech sounds affected cortical activity after the presentation period, especially in the long-distance brain networks.
The direct comparison between period 3 and period 1. (A) All the connectivity that showed higher correlations in period 3 in comparison with period 1 (p < 0.005). All the connectivity results were overlaid in a single figure. The bold lines indicate the connectivity that connects the frontal and temporal channels (four pairs in each hemisphere). (B) Individual data of temporal correlations normalized to z scores. The scatter plots show mean z scores in the four pairs indicated by the bold lines in each hemisphere in (A). The blue, red, and green circles indicate individual data of z scores during periods 1, 2, and 3, respectively. The black circles indicate mean values in each period. (C) The magnitudes of squared coherence between the frontal and temporal channels. We calculated the squared coherence of oxy-Hb signals between the four pairs in each hemisphere, shown in (A). The four values for each frequency were averaged for each infant. The blue, red, and green lines indicate the mean values in periods 1, 2, and 3, respectively (error bar: the SE). Data below 1 Hz were presented in each period. The abscissa and ordinate show the frequency in a log scale and the magnitude of squared coherence, respectively.
Interestingly, the four pairs in the left hemisphere showed increases from period 2 to period 3 (sign test, p < 0.05), while such a difference was not observed in the right hemisphere (p > 0.9). This trend was remarkable in the low-frequency band in the coherence analysis (Figure 9C). The coherence in lesser than 0.04 Hz of the left hemisphere was highest during period 3, while one in the right hemisphere did not show such a difference during periods 2 and 3. We conducted a two-by-two ANOVA (hemisphere, left and right; period, 2 and 3) using the values between 0.009 – 0.04 Hz, and found that the interaction was significant (F (1,20) = 4.58, p < 0.05). The simple main effect showed that the coherence of period 3 in the left hemisphere was higher than that in the right hemisphere (p < 0.01). These results indicate that the increase in correlations from period 2 to 3 was observed in the lower frequency of activation in the left hemisphere. Further, the coherence analysis suggests that the highest correlation of the left hemisphere during period 3 does not depend on signal fluctuations immediately after the end point of the speech presentation (period 2), but reflects activation of the fronto-temporal network in the left hemisphere during period 3.
To reveal the spatial formation of regions that had similar temporal correlations, we applied cluster analyses to the correlation coefficients calculated from oxy-Hb, deoxy-Hb, and total-Hb signals (Figure 10). In all periods, the four clusters showed bilateral patterns, in which clusters were formed across the midline and included homologous channels. The bilateral frontal, temporal, temporoparietal, and parieto-occipital regions formed clusters. The clusters above T3 and T4 (red cluster) based on oxy-Hb signals showed notable consistency in terms of spatial configuration in both the hemispheres across all three periods. However, when the cluster analysis was done based on total-Hb signals, the red cluster in the left hemisphere during period 3 extended to frontal and posterior temporal regions. The left–right asymmetry in the fronto-temporal direction was consistent with the result in the analyses above (Figure 9). Our findings are consistent with the idea that long-distance functional networks show lateralization in the infant brain.
Spatial configuration of the 4 clusters obtained by cluster analyses. We defined the distance between two channels by calculating 1 – r, and conducted cluster analyses. The four clusters in each period can be identified by coloring. The small dots are the landmarks shown in Figure 1B.
The present study demonstrated that extensive cortical regions of 3-month-old infants formed large-scale brain networks that are related to the processing of speech sounds. We found that not only the bilateral temporal and temporoparietal regions, but also the prefrontal and occipital regions showed oxy-Hb signal increases and deoxy-Hb signal decreases when speech sounds were presented to the infants. While the bilateral regions were responsive to speech sounds, a hemispheric difference was marked in the fronto-temporal networks. Our correlation analyses revealed long-distance functional connectivity in the antero-posterior direction during and after the presentation of spoken sentences, suggesting that the large-scale brain networks of infants provide the foundation for speech processing.
The hemispheric difference in speech perception in infancy is one of the greatest questions in the developmental cognitive neurosciences. An NIRS study on neonates was reported by Kotilahti et al. (2005), in which the bilateral temporal regions were responsive to sinusoidal tones. This bilateral activation in response to auditory stimuli was reproduced by Telkemeyer et al. (2009). They showed not only bilateral activation, but also right lateralization in response to slow acoustic modulations. These studies suggest that speech sounds, including both rapid and slow changes, induce bilateral activation in the temporal regions. This suggestion has been supported by multiple NIRS studies of infants (Homae et al., 2006, 2007; Minagawa-Kawai et al., 2007; Taga and Asakawa, 2007; Nakano et al., 2008, 2009; Bortfeld et al., 2009; Kotilahti et al., 2010; Sato et al., 2010). It is informative to investigate activation in the bilateral auditory regions, when speech sounds and other sounds are presented, before testing hemispheric differences in signal intensity. We consider that if the bilateral activation in auditory regions is not observed under conditions of auditory-stimulus presentation, we have to carefully examine the auditory/speech stimuli, tasks, and probe settings in NIRS measurements of the study.
In the present study, we found that the bilateral cortical regions were responsive to speech sounds, and there were no significant differences in the amount of signal changes between homologous regions. We presented only normal speech in period 2, and thus both segmental and suprasegmental information is included in all the stimuli. In such a case, infants would perceive and process both rapid and slow changes in acoustic/speech information, resulting in a similar degree of activation in the left and right hemispheres. A lateralized activation pattern would emerge if some features in speech sounds were highlighted by the presentation of multiple types of speech stimuli. In our previous studies, we presented normal and flattened speech sounds to infants and found the right-lateralized activation pattern in the temporoparietal region related to processing pitch information in speech sounds (Homae et al., 2006, 2007). In the present study, we observed significant activation in the temporoparietal regions in both hemispheres, and an increase in correlations between the right temporoparietal region and the right prefrontal region in period 2. The connectivity was right-lateralized and the increase was not observed in the left homologue. These findings and our previous studies suggest that the prosodic information in normal speech would be processed in the right-lateralized network.
The speech sounds we presented in period 2 induced bilateral activation in extensive cortical regions posterior to the temporal regions, including the occipital regions. These distributed activation patterns in sleeping infants have been observed in our previous studies, but the present result is the first demonstration of oxy-Hb increases and deoxy-Hb decreases in the occipital regions. The oxy-Hb and deoxy-Hb signal changes indicated the neural responses, in these regions, to the speech sounds. There are at least three possibilities that explain this broad activation. First, corticocortical connections convey the information from the temporal region to the posterior regions. In the perinatal period, the temporal lobe expands and the auditory cortex develops. Mature axons in the auditory cortex, which run parallel to the cortical surface for long distances, are present in the most superficial layer (Moore, 2002). These axons could be related to cortico-cortical connections. Second, direct connections between the auditory and visual cortices subserve the information transmission. Although the direct pathway has not been clarified in infants, neurophysiological and neuroimaging studies on animals and human adults provide multiple evidence (Bavelier and Neville, 2002; Falchier et al., 2002; Rockland and Ojima, 2003; Eckert et al., 2008). An fMRI study on adults reported that the visual cortices showed responses to the auditory stimuli and the peak times of the signal changes in the visual cortex were later than those in the auditory cortex (Martuzzi et al., 2007). This trend is observed in our study. If the speech information is conveyed to the auditory regions in the cerebral cortex firstly, the activation in the visual cortex would not precede to the activation in the auditory cortex. Third, the thalamus plays a role in the transmission from the auditory cortices to the visual cortices. Audio–visual interaction via the thalamus has been reported in the early stages of audio–visual processing (Baier et al., 2006; Noesselt et al., 2010). It is possible that activation in the medial geniculate body induces activation in the lateral geniculate body and the visual cortices in the sleeping infants. In awake infants of 2- to 4-months old, in contrast, activation in the perisylvian regions and deactivation in the occipital region were reported in an fMRI study (Dehaene-Lambertz et al., 2006). Thus, infants’ wakefulness would determine the activation pattern in the occipital regions. Excitatory and inhibitory balance in the visual regions of infants might depend on awake/sleep states or stimulus differences. Future studies are needed to clarify the mechanisms of extensive activation in the posterior regions and their dependency on infants’ wakefulness.
The correlation between the left occipital regions and the left frontal regions were high in period 2. We have reported that the correlation between these regions in the resting state exhibited U-shaped changes: It was lowest in 3-month-old infants in comparison with neonates and 6-month-old infants (Homae et al., 2010). A recent resting-state fcMRI study reported consistent results on neonates. The right dorsolateral prefrontal cortex had functional connectivity with the left homologous region and the bilateral precuneus (Fransson et al., 2011). The present results demonstrate that the left fronto-occipital network in 3-month-old infants could be activated if speech sounds were presented, although physiological confounds, including respiratory, cardiovascular, and blood pressure oscillations, should be carefully considered. One anatomical basis connecting these regions might be the occipitofrontal fascicle, which was traced in a DTI study on adults (Makris et al., 2007). The potential role of this fascicle in adults is visual processing, but its role in early infancy is not yet known. We observed significant activation in the occipital regions and the frontal regions only in period 2 and connectivity between these regions in the period. Because speech sounds were presented in period 2, speech sounds would modulate activity in the occipital and frontal regions and the fronto-occipital connectivity. We propose a possibility that the fronto-occipital network might make some contribution to the perception of speech sounds in sleeping infants.
To date, functional studies on infant brain networks mainly dealt with no-stimulus conditions and reported the precursors of default-mode networks (Fransson et al., 2007; Gao et al., 2009). Recently, we found the development of global cortical networks in the infant brain (Homae et al., 2010): The resting-state connectivity between homologous regions in the temporal and posterior cortices, and the connectivity between the left temporal and parietal regions, are strengthened from neonates to 3- and 6-month-old infants. However, the relationship between the frontal and temporal regions was not evident in the resting state of infants, in contrast to connectivity between the left frontal and temporal regions in the resting state of adults (Zhang et al., 2010). Our previous studies (Homae et al., 2007; Nakano et al., 2009) and those of others (Imada et al., 2006; Gervain et al., 2008) show co-occurrence of activation in the temporal/temporoparietal and frontal regions when speech sounds are presented, leading us to hypothesize that the fronto-temporal networks begin to function during early infancy. The presentation of speech sounds would change the state of networks including these regions. In the present study, we clarified that the connectivity between the prefrontal and posterior portions of the temporal regions was high in both hemispheres under the stimulus presentation condition (period 2). The anatomical connection between the prefrontal region and the temporal/temporoparietal region has been reported in primate studies (Petrides and Pandya, 1988; Romanski et al., 1999) and in human studies using DTI (Makris et al., 2005; Tomassini et al., 2007). In the infants, a small tract of the superior longitudinal fasciculus and the arcuate fasciculus connecting these regions was identified and reconstructed by tractography of DTI (Zhang et al., 2007; Dubois et al., 2009). These studies suggest that these anatomical connections, at least partly, exist in infancy. Our results are consistent with the hypothesis that the fronto-temporal networks begin to function in infancy, and may play a role in the processing of speech sounds.
Speech sounds affect brain activation of infants even after the presentation has ceased. The comparison between the functional connectivity in a no-stimulus condition before and after the speech-stimulus presentation revealed resultant modulation of speech sounds in the bilateral fronto-temporal connectivity. Pairs in the left hemisphere that showed high correlations in period 3 did not exhibit significantly high correlations in the period 2 (Figures 8A and 9A). This implies that high correlations in period 3 were not remainders of activation in the period 2, but the reflection of co-activation of these regions during period 3. The findings of this study demonstrate that the functional network of the infant brain is state-dependent, and further, it may suggest that the functional network works as a hysteresis system that has a memory of the previous inputs. Hysteresis in the neural mechanisms is, in principle, related to learning and development. A recent fMRI study reported that motor learning by 11-min visuomotor training can modulate subsequent activity within resting-state networks (Albert et al., 2009). The hysteresis system that we found in the infant brain would be involved in the learning of speech perception and language acquisition.
The possibility that the left and right functional networks play distinct roles is suggested by the hemispheric difference in the networks between periods 2 and 3. The left fronto-temporal network showed higher correlations in period 3 in comparison with those in period 2, whereas such a difference was not observed in the right network. The candidate roles are, for example, that the right network is involved in retaining speech information and the left network produces some representation that is relevant to speech information. The coherence analysis revealed that the high correlations in the left networks mostly depended on synchronization in the lower frequency. Our findings allow us to propose the hypothesis that the large-scale (long-distance in spatial and long-range in temporal) connectivity between the frontal and temporal regions underlies the speech processing of infants. The large-scale brain networks would enable the processing of internal and external information hierarchically and recursively, which might constrain language acquisition in infancy. These networks are supposed to be dynamic and not static, and thus, their roles would vary during the course of development. The accumulation of knowledge of the functional networks in the developing infant brain, as well as data on functional brain mapping, opens up a new field – the developmental brain science of language – and will further clarify how and why infants acquire their native languages.
The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.

Placeboxetine for major depressive disorder: Researcher, author, reader, and reviewer perspectives on randomized controlled trials

Postgraduate students, budding authors, clinicians who read journals, and new reviewers need to develop skills in reading, writing, and reviewing papers that describe randomized controlled trials (RCTs).
This commentary critically examines a specially-written paper (published in the same issue of this journal) that describes a fictitious, industry-driven, multicentre RCT comparing the fictitious antidepressant placeboxetine with sertraline in Indian patients with major depressive disorder. Readers are invited to independently assess the RCT paper before they continue with this commentary.
Scientific aspects of the design and execution of the RCT are examined in the context of ethical issues in research. Comments and suggestions are offered on issues such as the statistical handling of data, manuscript content, and manuscript writing style. The reader's attention is drawn to subtle and not-so-subtle errors, as well as to curiosities in the data.
It is hoped that this practical commentary on research design, execution, analysis, and reporting, based on specific examples, will benefit researchers, authors, readers, and reviewers more than guidance delivered in the form of general advice.

The Indian Journal of Psychiatry receives many more manuscripts than it can publish. Some of these manuscripts, though academically important, are insufficiently well written to merit acceptance. Many manuscripts require several rounds of peer review before an editorial decision is taken. In both situations, and especially in the latter, the editorial office and the reviewers of the manuscripts are taxed; this wastes time and resources, and the waste is a complete loss for all involved if the manuscript is eventually rejected. A further consideration relates to intellectual ethics. When authors submit a substantially substandard article which is eventually accepted after extensive reviewer inputs, intellectual credit for the publication actually belongs to the reviewers; however, such credit is never paid. There is, therefore, no incentive for reviewers to take trouble over an inferior manuscript, and this may be why many journals have a policy of rejecting manuscripts outright, without review, if a quick scan reveals serious weaknesses.
The present article illustrates concerns that arise when designing a randomized controlled trial (RCT), executing the study, analyzing the data, and preparing the manuscript for publication. As volumes have been written on the subject, the present article has a more practical objective: to base comments and suggestions on a specially-prepared paper[1] describing a fictitious RCT of a fictitious antidepressant placeboxetine. Readers may note that this prepared paper[1] is based on actual flaws identified in manuscripts submitted to the Indian Journal of Psychiatry.
It is hoped that the comments and suggestions provided in this critique will benefit RCT investigators, RCT authors, clinicians who read journals, postgraduate students who are learning how to critically evaluate a paper, and newly-recruited journal reviewers who scrutinize manuscripts that describe RCTs. A previous article in this series provided guidance on how to write a good case report.[2]
Common shortcomings in manuscripts submitted to the Indian Journal of Psychiatry were collated into a single manuscript which has been published in this issue of the journal[1] as a fictitious RCT comparing the fictitious antidepressant placeboxetine (PB) with an active control, sertraline, in Indian patients with major depressive disorder (MDD).
The fictitious RCT and the paper[1] describing it are critically examined from the perspectives of study design, study execution, data analysis, presentation of findings, and manuscript content and style. Readers are invited to first read the prepared paper[1] in full and form their own judgement before reading the following sections. This critique is not exhaustive; readers may identify more flaws in the RCT paper than are listed in this critique.
When patients participate in clinical research, they expose themselves to a variety of risks. For example, they may receive an experimental agent of uncertain efficacy and adverse effects. Or, they may receive placebo and thereby experience little to no benefit for the duration of their participation in the study. Or, if they receive an active control medication, they may receive it in a dosing schedule that is protocol-driven rather than suitable to their individual requirement. Furthermore, they are required to make extra hospital visits, cooperate in a number of rating procedures, provide blood samples for required safety assessments, and otherwise considerably inconvenience themselves during the course of the study. They receive no monetary reward for their cooperation. Their participation is altruistic because it is expected to benefit the cause of science and guide the treatment of future patients. Scientists who conduct clinical research are therefore ethically obliged to ensure that their study is necessary; that it is well-designed and conducted; and that the report is published. Otherwise, their patients would have wasted their time and have exposed themselves to medical risks for no worthwhile purpose.
Although the paper[1] describing the fictitious RCT does not explicitly state as much, it was very likely a regulatory study conducted to fulfil the Drug Controller General of India requirements for the licensing of placeboxetine in India. Therefore, at least some of the criticism in this commentary is also an indictment of the regulations which necessitated such a study without setting research standards.
The review of literature in the RCT referred to four regulatory trials on the safety and efficacy of the PB in MDD. Therefore, if a new study was to have been conducted, it should have been superior to the existing trials in design and methods, or it should have answered a new question. The described RCT[1] falls short in the former regard, with failings in the domains of study design [Table 1], study execution [Table 2], and statistical methods [Table 3]. The study does, however, address a new question: Is PB safe and effective in Indian patients with MDD? Regrettably, in consequence of the identified shortcomings [Tables 1–3], many of which are irremediable, the results of the study cannot offer a reliable answer.
Important limitations in the study design
Important limitations in the study execution
Important limitations in data handling and statistical procedures
Precision writing describes the ability to convey a message with clarity and brevity, and every word should serve a necessary purpose. In this context, consider the title of the article; it is 27 words long and runs into three lines. Can the title have been more succinctly expressed? Here are two possibilities: “A randomized controlled trial of the safety and efficacy of placeboxetine in Indian patients with major depressive disorder” or “A randomized controlled comparison of placeboxetine and sertraline in Indian patients with major depressive disorder”. These titles are as informative as the original but are shorter by a third or more. Precision writing is also considered in the next subsection, which deals with the abstract.
Consider the first sentence of the methods subsection of the abstract. This sentence reads “In a prospective, open-label, 15-center, randomized controlled clinical trial, consecutive outpatients diagnosed with major depressive disorder of at least moderate severity were randomized 1:1 to receive flexible doses of either PB or sertraline once each morning.” In this sentence, ‘prospective’ is unnecessary because all RCTs are prospective; ‘15-center’ is unnecessary because it has already received mention in the background subsection; ‘randomized’ is unnecessary because the latter part of the sentence refers to randomization. Several other elements in the sentence do not really need to be described in an abstract. The sentence could have been more succinctly expressed as ‘Outpatients with major depressive disorder that was at least moderate in severity were randomized to receive flexibly dosed, open-label PB or sertraline.’
Content that is obvious need not be included in an abstract; an example is the sentence on tolerability assessments, appearing in the methods subsection. This is because tolerability is always assessed in RCTs and therefore does not require especial mention in the abstract unless a special instrument is used or a special adverse event is monitored. Abstracts, however, should mention the sample size and the number of subjects in each treatment group; this information was not provided. Furthermore, abstracts should provide information on dosing of the study medications and the duration of the study; these data were also missing. It is also usual for the primary outcome measure to be specified in the abstract; and, when terms such as response and remission are used, these need to be defined. Some journals additionally require the abstract to state the period during which the study was conducted. Finally, the results subsection of the abstract should have contained information on the adverse events recorded with the two treatments.
In RCT reports, it is usual to provide a CONSORT diagram which serves as a study flow chart that also describes patient disposition across the course of the study. The CONSORT diagram was not provided.
In the RCT Table 1, data should have been corrected to the first decimal place; two decimal places provide unnecessary precision. Data on baseline weight and blood pressure need not have been included in the table; neither was an especial focus of the study, and neither was further described with data in the results and discussion.
The RCT manuscript included more tables than were required. As content in tables should not be repeated in the text (and vice versa), the RCT Table 2, which presented the response and remission rates, was unnecessary. Next, it is not usual to present laboratory data such as the metabolic information [RCT Table 4], especially when the findings were entirely unremarkable and not an especial focus of the study. With regard to these data, however, there is a curiosity in the values at baseline. In both groups, the baseline standard deviations were very large; at endpoint, the mean values were (nonsignificantly) diminished, and the standard deviations were substantially reduced. Possible explanations are that nonfasting blood samples were drawn for some patients at baseline, resulting in high metabolic parameter values; or that some of the baseline laboratory assessments were faulty; or that some patients truly had elevated glucose and lipid levels at baseline, and appropriate treatment was instituted.
Information missing from the report
Necessary details that were not provided in the paper include issues related to ascertainment of adverse effects, medication compliance, discontinuation symptoms, and other matters; these are listed in Table 4 in this paper.
The first paragraph of the Results section of the RCT paper presents data on drop outs. Twenty patients did not complete the study; however, when the reasons for drop out are examined, it appears that 21 patients dropped out.
In the RCT Table 1, the mean age of the patients in each group should be the sum of the mean age at onset of illness and the mean duration of illness. This addition is correct in the sertraline group but not in the PB group.
In the RCT Table 1, there is a striking difference between groups in the standard deviations of the age variable. It is likely that the very small standard deviation for age in the sertraline group is an error.
Some unusual aspects of this report draw the reader's attention. There were only 9 screening failures among 209 consented patients; this is a strikingly low figure for a multicenter study. The response and remission rates were at or above 90% and 70%, respectively; both figures are exceptionally high even for an open study. As many as 90% of the randomized patients completed the 6-week study; this figure is also markedly high. The incidence of sexual dysfunction was low, and no cases of ejaculatory delay were recorded. No cases of agitation or restlessness were recorded as adverse events, either. Most reviewers would consider these data to be too good to be true. Alternately, the patients may have been atypical, or the raters too ready to declare improvement and too lax in the recognition and registration of adverse effects.
There were other limitations in the manuscript; some minor, and others not so minor. For example, the abstract observed that the study enrolled outpatients; this should also been mentioned in the Methods section of the text. The introduction referred to the incidence of depression; the figures stated describe lifetime prevalence rather than incidence. Both abstract and text refer to the Montgomery-Asberg Rating Scale instead of the Montgomery-Asberg Depression Rating Scale. The male predominance of the sample was unusual and should have received comment. The discussion should have addressed the high response and remission rates, unusual for clinical trials. There should have been a subsection in the discussion on the limitations of the study. In general, the discussion should have been more extensive for a study of this magnitude.
How can investigators avoid such limitations in their trials and their manuscripts? Here are some very simple and easily implemented suggestions:
Base the research design and study procedures on previous research protocols; adopt methods described in previously published studies (of a similar nature) in leading journals; seek guidance from experts in the field.Use a previously published study (of a similar nature, in a leading journal) as a template for preparing the manuscript, proceeding section by section, table by table, and figure by figure; obtain the assistance of a professional statistician; have the final manuscript vetted by experienced colleagues and a language expert.
Base the research design and study procedures on previous research protocols; adopt methods described in previously published studies (of a similar nature) in leading journals; seek guidance from experts in the field.
Use a previously published study (of a similar nature, in a leading journal) as a template for preparing the manuscript, proceeding section by section, table by table, and figure by figure; obtain the assistance of a professional statistician; have the final manuscript vetted by experienced colleagues and a language expert.

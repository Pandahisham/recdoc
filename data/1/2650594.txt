Lung volume reduction surgery and lung transplantation in chronic obstructive pulmonary disease

Medical treatment of emphysema does not alter the natural progression of the disease. Surgical techniques are an attractive conceptual approach to treat hyperinflation in these patients. Lung volume reduction surgery and lung transplantation are appropriate therapeutic options for a selected population with emphysema. We will review the available evidence to support these approaches.

Emphysema is a progressive, debilitating disease characterized by an irreversible destruction of alveolar septa. Medical therapy undoubtedly provides symptomatic improvement, however, it does not alter the natural progression of the disease. As a consequence, chronic obstructive pulmonary disease (COPD) continues to be one of the leading causes or morbidity and mortality worldwide, and places a significant economic burden over individuals and society. In the United States, expenditures for Medicare beneficiaries with COPD are nearly 2.5 times higher than per capita total expenditures of those without COPD (US$8,482 vs US$3,511) (Sullivan et al 2000). Chronic lower respiratory diseases represented the fourth leading cause of death in the United States in 2005 (mortality rate was 44.2 per 100,000 population), showing no significant variation within the last 5 years (Kung et al 2008).
Since altered respiratory mechanics play a pivotal role in the pathophysiology of emphysema, manipulation of the intervening structures by means of surgery have been seen as an attractive approach for several decades. The history of such approaches has been elegantly reviewed elsewhere (Deslauriers 1996). We will attempt to provide an evidence-based perspective to the current views on how to surgically manage emphysema, focusing on lung volume reduction surgery (LVRS), and lung transplantation. A PubMed search was conducted utilizing the terms “lung volume reduction surgery”, “lung transplantation”, and “chronic obstructive pulmonary disease”. Relevant publications were selected based on level of evidence; randomized controlled studies were preferred when available. Otherwise, the best available level of evidence literature was chosen. Emphasis was made on the last ten years, although studies that had historic relevance were also included. Although results may appear somewhat encouraging, this fact is shadowed by the fact that very few patients with emphysema are eligible for surgical treatment; this is particularly true for those with advanced and debilitating disease where medical treatment is clearly ineffective.
Physiologically, emphysema is characterized by decreased elastic recoil, increased lung compliance, early airway closure, air trapping, overexpansion of the rib cage and flattening of the diaphragm. Dynamic airway compression creates trapped areas within the lung parenchyma. This compression is more evident at high lung volumes, and becomes manifested in emphysema, producing increased thoracic gas volume. Spirometrically this is evidenced by decreased forced vital capacity (FVC) and forced expiratory volume in one second (FEV1), along with hyperinflation.
When a portion of a hyperinflated emphysematous lung is surgically removed, the remaining portion of the lung stretches within the thorax. An unchanged chest wall operating on a smaller lung restores the elastic recoil (Loring et al 1999), and expiratory flows at any given lung volume increase on the basis of increased airway traction and delayed airway closure. LVRS translates into reduced thoracic gas compression by improving expiratory flow limitation: FEV1 is consistently improved, and both total lung capacity (TLC) and residual volume (RV) are reduced. (Sharafkhaneh et al 2005) Diaphragmatic muscle fiber length and geometry is also optimized (Gorman et al 2005), likely decreasing respiratory effort, and producing a theoretical improvement in dyspnea.
Oxygen consumption and resting energy expenditure are increased in emphysema because of impaired respiratory mechanics, with greater oxygen cost of breathing and substrate oxidation that favors lipid catabolism. Lung volume reduction surgery significantly decreases proportional oxygen consumption of respiratory muscles and resting energy expenditure over respiratory rehabilitation. Correlations with residual volume and nutritional status suggest that restoration of respiratory mechanics reduces energy expenditure and approximates metabolism to normal (Mineo et al 2006).
Disruption of the lung parenchyma, as seen in emphysema, adversely affects cardiovascular function. Pulmonary endothelial dysfunction (Fira-Mladinescu et al 2007), persistent hypoxemia and decreased cross-sectional area of the pulmonary system translates in increased pulmonary vascular resistance and increased right ventricular afterload. Overtime, the right ventricle will remodel and may compromise left ventricular filling and function by altering interventricular septal geometry. Conceptually, a therapeutic intervention able to improve gas exchange, and improve ventilation-perfusion matching, would ameliorate the deleterious hemodynamic consequences of emphysema. Although LVRS may accomplish this purpose, removal of lung parenchyma also removes lung vasculature, and necessarily produces physical deformation of lung vessels. It appears LVRS does not produce a significant difference in pulmonary artery pressures as measured six months after the procedure (Criner et al 2007).
The first physiology-oriented surgical approach to manage emphysema dates back to the 1950’s when Brantigan hypothesized that surgical reduction of lung volumes would translate in restoring of radial traction. Surgical techniques have varied over the years. Commonly utilized approaches include median sterenotomy (MS), standard thoracotomy, and video assisted thoracic surgery (VATS) (Martinez and Chang 2005). The use of a less invasive approach such as VATS seems to translate in reduced postoperative cytokine release, and hence, reduced postoperative infections and mechanical ventilation times (Frisca et al 2007). Although no definitive consensus exists, improvement seems to be greater with bilateral procedures regardless of the approach (Ocy el al 2002).
Bronchoscopic novel techniques, where airways leading to hyperinflated lung segments are instrumentally obstructed leading to distal collapse and reduced hyperinflation seem promising based on published case series (Hopkison 2007). Unilateral procedures seem to produce better physiologic outcomes. Which patients benefit the most and selection criteria are still to be determined (Wan et al 2006).
The assumption that physiologic improvements would translate in symptomatic improvement and may alter the natural history of emphysema served as the basis for LVRS as a therapeutic option for emphysema. Isolated short case series and small randomized trials suggested that selected patients might benefit from LVRS showing improvements in expiratory flow, exercise capacity and quality of life. The Washington University group showed a 90-day mortality rate of 4%, with modest postoperative complications (Cooper et al 1996). Other series reported comparable low rates of initial procedure- inherent complications and early physiologic improvement – improved FEV1, reduced TLC and RV, and improvement in six-minute walk distance (6MWD) test (Criner et al 1999; Pompeo et al 2000; Geddes et al 2000). Not surprisingly for a procedure being initially offered as palliative, quality of life assessments were also positive (Ciccone et al 2003). These encouraging results were not as impressive in Medicare-based data. Early 30-day postoperative mortality was reported to be as high as 23% (DHHS 1998); poor preoperative patient selection was probably a major determinant of these outcomes. Aside from the fact that these trials were arguably methodologically flawed, none of them showed an effect on mortality (Lederer and Aracsoy 2007).
When one systematically reviews the literature it becomes obvious that perhaps the strongest evidence to date comes from the National Emphysema Treatment Trial (NETT) (Fishman et al 2003). A large, prospective, randomized, multicenter, long-term study, the NETT compared optimal medical care to bilateral LVRS using median sternotomy (70%) or VATS (30%), added to medical therapy. The results of this trial were published in 2003 after a median two-and-a-half year follow-up, and again in 2006 after a median approximate four-year follow-up (Naunheim et al 2006). The 90-day mortality rate was significantly higher in the surgical group (7.9% vs 1.3% in the medical group, p < 0.001); this difference was not related to the surgical technique chosen. Despite this early mortality in the surgical group (the “pay-up-front” effect), there was no significant difference overall mortality between the two groups (Fishman et al 2003). However, there was a 6.6% absolute mortality reduction in the LVRS arm in the extended follow-up report (Naunheim et al 2006). As suggested by studies predating the NETT trial (Flaherty and Martinez 2000), LVRS had a positive physiologic impact. Exercise capacity improvement was significantly higher in the surgical over the 24-month follow-up period, as demonstrated by improved 6MWD, and percentage. Health-related quality of life and predicted FEV1 dyspnea also improved significantly more in the surgical group (Fishman et al 2003).
The presence of homogenous emphysema or preoperative carbon monoxide diffusing capacity of 20% or less of predicted, along with an FEV1 of 20% or less of predicted, were clearly associated with a high-risk of death after LVRS and minimal functional benefit as identified early in the NETT trial; within 30 days following surgery the mortality on this group was as high as 16%, and after 6 month 33% have died (Fishman et al 2001). This high-risk group of patients is clearly unsuitable for LVRS.
A post hoc analysis identified a subgroup that may potentially benefit from LVRS (Fishman et al 2003), and more importantly, it was a able to identify a subgroup of patients in whom LVRS may be detrimental. The craniocaudal distribution of emphysema and the base-line exercise capacity were showed to be predictive of LVRS benefit. Patients with predominantly upper-lobe emphysema and low exercise capacity preoperatively benefited from LVRS: they showed significantly lower mortality, improved exercise capacity and improvement in standardized symptom scores as compared with the medical-therapy group. On the other hand, in patients with non-upper lobe disease and high exercise capacity, LVRS translated in a higher risk of death. The risk of death was not significantly modified by surgery in other groups with different anatomical distribution of emphysema and exercise capacity combinations (Fishman et al 2003).
The NETT genetics ancillary study involved a cohort of 282 patients in whom tomographic emphysema phenotypes were correlated with genetic polymorphisms for association with emphysema distribution. Polymorphisms in the xenobiotic metabolizing enzymes GSTP1 and EPHX1 are associated tomographic apical-predominant emphysema (DeMeo et al 2007). Furthermore, the presence of these enzymatic genotypes predicted a better response to LVRS, as evidenced by reduction in BODE score; this improvement was more significant in the patients with low exercise capacity (Hersh et al 2007). Genetic characterization of emphysema may well be a screening tool in the future allowing to determine those patients that may benefit from LVRS.
Alpha-1 antitrypsin (AAT) deficiency patients have been excluded from most LVRS trials. However, 10 of the subjects randomized in the NETT trial had severe AAT deficiency. When outcomes were compared between AAT-deficient patients undergoing LVRS and those with normal levels, rise, deficient individuals had a shorter duration in FEV1 smaller increase in exercise capacity at 6 months, and higher mortality. Although these conclusions are inherently limited by the small number of patients analyzed, LVRS cannot clearly be recommended for this population based on the above data (Stoller et al 2007). In addition, most patients with AAT deficiency have lower lobe predominant emphysema, which showed the least surgical benefit in NETT (leading to worse outcomes in good exercise capacity patients).
The efficacy of traditional bronchodilator and anti-inflammatory therapy to prevent COPD exacerbations continues to be a debatable subject. Although prospective analysis of the effect of LVRS on COPD exacerbation was not one of the end-points of the NETT trial, a recent post-hoc analysis based on medical claims data on patients who took part on the NETT trial shows a significant reduction in the frequency of exacerbations (30%, P = 0.00005) in the surgical cohort; this difference is even more marked in those patients in improvements. The time whom surgery produced larger FEV1 to the first exacerbation was also better for the surgical group (Washko et al 2008). These correlations, although attractive, do not necessarily mean that LVRS reduces COPD exacerbations. It is possible that the improved baseline perception of dyspnea achieved by the LVRS group translates in a reduced frequency of emergent care, and a consequent reduction in reported claims.
In parallel to the NETT trial, a prospective, economic analysis was performed (Ramsey et al 2003) showing a cost of US$190,000 per quality-adjusted life year (QALY) for LVRS compared to optimal medical care after a three-year follow-up period. Based on extrapolation models, it was forecasted that after ten years this amount would be US$21,000 for the group that showed the most benefit after LVRS, ie, upper lobe, low exercise capacity. This determination translated in Medicare covering for the procedure in all groups of the NETT trial with the exception of those with non-upper-lobe disease and high exercise capacity. A recent report (Ramsey et al 2007) based on an actual 5- to 10-year follow-up of the NETT cohort showed that the above extrapolations greatly overestimated the cost-effectiveness of LVRS. The actual CE was $48,000 per QALY at 10 years in the upper lobe, low exercise capacity group. However, this fact is unlikely to change the way Medicare reimburses for LVRS, given the supportive clinical evidence.
In 2005, the worldwide number of lung transplantations reached approximately 2100. Two thirds of these operations are done in the United States (Pierson et al 2004; Trulock et al 2005). The first lung transplant for COPD in the modern era was performed in 1986. Since then COPD has become the most common indication for lung transplantation (Trulock et al 2005) accounting for 45.9% of all lung transplants (38.0% emphysema and 7.9% alpha-1-antitrypsin deficiency). These ratios have changed in the United States since the implementation of the new lung allocation system in May 2005. As a result in 2005 COPD accounted for only 31.4% of transplants in the United States and alpha-1-antitrypsin deficiency accounted for 3.6%. These numbers decreased further in the United States in 2006 to 30.1% and to 3.2% respectively (OPTN 2008). However, COPD and alpha-1-antitrypsin deficiency remain the most common diagnoses for which lung transplantation is performed (OPTN 2008). For the rest of this review the term COPD will be used to describe both COPD and alpha-1-antitrypsin deficiency unless otherwise specified.
After early fears that single lung transplantation (SLT) would not be feasible because of native lung hyperinflation (Venuta et al 1999), it became obvious that both SLT and bilateral lung transplantation (BLT) offer good options for patients with COPD (Pochetino et al 2000). They both offer similar short-term outcomes (Pochettino et al 2000), but BLT appears to provide superior long-term outcomes (Meyer et al 2001; Cassivi et al 2002; Hadjiliadis et al 2006). On the other hand SLT offers transplant to two patients, rather than one and it can potentially reduce waiting list times (Hadjiliadis et al 2006b). In recent years percentage of BLT transplants for COPD has increased (Trulock et al 2007). However, no randomized trials have evaluated the relative merits of each operation and there are inherent biases (local and national) while selecting BLT vs SLT for a specific patient. Therefore the best operation for each patient should be selected on an individual basis.
Unfortunately, no studies have demonstrated a consistent transplantation survival advantage for this group of patients when analyzed as a whole (grouping SLT and BLT recipients) post-transplantation. A large review using data from the US registry suggested that lung transplantation for COPD did not prolong survival (Hosenpud et al 1998). However, two smaller European studies suggest that lung transplantation for COPD did improve survival, albeit to a lesser extent when compared to other diagnoses (De Meester et el 2001; Charman et al 2002). The disparity between these studies may come from the fact that the European centers involved used a severity of illness allocation system, while those centers in the US registry utilized waiting time to allocate organs under the prior allocation system. No study has examined whether lung transplantation offers a potential survival advantage for patients with COPD after the implementation of the new Lung Allocation Score in the United States, which offers lungs based waiting list urgency and transplant benefit.
In general, patients referred for lung transplantation have to suffer from severe disease that cannot be medically managed (Orens et al 2006). Unlike LVRS, transplantation can be offered to patients who have more severe disease and in fact it is geared towards that group (Patel et al 2008). In addition, patients have to be free of other significant medical comorbidities, including heart disease, liver disease or renal failure (Orens et al 2006). They also need to have no significant psychiatric illness and adequate financial and psychosocial support (Orens et al 2006). Absolute contraindications to lung transplantation include any of the above-mentioned medical comorbidities and uncontrolled or untreatable infection (Orens et al 2006); recent cancer (Orens et al 2006). Relative contraindications include active hepatitis C without cirrhosis, medically or surgically treated coronary disease, prior thoracic surgery (especially with pleurodesis and/or chest wall deformity), acute critical illness, advanced age (most programs consider 65 years the upper age limit for lung transplantation), poor nutritional status (over or underweight) and physical debilitation (Orens et al 2006). Lung transplant centers differ on their philosophy of accepting high-risk candidates and what contraindications they consider more important on the selection process.
Specific selection criteria for referral for transplant for patients with COPD include patients with FEV1 < 25%, BODE index of 5 or higher (Orens et al 2006). Timing of actual listing for lung transplantation is reserved for patients with acute hypercapnea in the setting of hospitalization, pulmonary hypertension or cor pulmonale in the setting of adequate oxygen therapy, BODE index of 7 or higher and FEV1 of less than 20% with DLCO of less than 20% or homogeneous distribution of emphysema (Orens et al 2006).
Survival after lung transplantation has improved over the last few years, however it remains limited. One year, 3-year, 5-year and 10-year survival for patients receiving BLT vs SLT are 83.8% vs 80.5%, 67.8% vs 62.5%, 56.3% vs 46.5% and 30.1% vs 17.7%, respectively (p < 0.001) (Trulock et al 2007). However, SLT recipients tend to be older and have more comorbidities in most centers, so these results are difficult to assess with respect to the merit of each operation (Meyer et al 2001; Cassivi et al 2002; Hadjiliadis et al 2006). From the survival statistics it is obvious that only patients with the most severe disease are likely to benefit from this procedure.
Lung transplantation dramatically improves most physiologic parameters of patients with COPD. FEV1 and FVC improve, while TLC and RV tend to normalize; in addition, need for oxygen disappears and carbon dioxide normalizes. Six-minute walk distance improves dramatically too (Levine et al 1994; Sundaresan et al 1996; Bavaria et al 1997; Pochettino et al 2000; Cassivi et al 2002). The improvements seen after lung transplantation are more dramatic compared with LVRS although no study has made a head to head comparison of similar group of patients. Studies have compared the two procedures and they have showed increased mortality with transplant; however, in all studies transplant was reserved for patients with more advanced COPD (Weinstein et al 1997; Meyers et al 2001). When patients receiving BLT are compared with SLT recipients all parameters tend to be better in the BLT group, although even SLT recipients have very significant improvements in all parameters (Levine et al 1994; Sundaresan et al 1996; Bavaria et al 1997).
Quality of life significantly improves after lung transplantation for COPD. No prospective trial has assessed the same group of patients before and after transplant in a longitudinal fashion. However the changes in cross sectional studies are highly significant (Anyawu et al 2001; Gerbase et al 2005). In another study, utilizing the survival analysis from the patient with Hosenpud, showed that despite a possibly worse survival in patients with COPD after lung transplantation, their quality of life-adjusted years were better after lung transplantation (Singer et al 2002).
There are many complications after lung transplantation that contribute to its high mortality. Patients after lung transplantation have to take multiple medications, including three immunosuppressive agents in most cases (calcineurin inhibitor: cyclosporine or tacrolimus; cell cycle inhibitor: azathioprine or mycophenolate mofetil; prednisone) (Arcasoy and Kotloff 1999; Trulock et al 2007). Despite the heavy immunosuppression, acute rejection occurs frequently after lung transplantation and it frequently requires high doses of steroids for treatment. In addition, many patients develop obliterative bronchiolitis (chronic rejection) by 5 years after lung transplantation (Arcasoy and Kotloff 1999; Trulock et al 2007). The immunosuppressive regimen makes patients susceptible to infections, including aspergillus, cytomegalovirus, and other respiratory viruses, and they constitute the second leading cause of death among lung transplant recipients (Arcasoy and Kotloff 1999; Trulock et al 2007). The medications also lead to increased risk of hypertension, hyperlipidemia and diabetes mellitus (Arcasoy et al 2007). As a result, many patients also develop progressive renal failure, as the cumulative exposure to calcineurin inhibitors increases (Arcasoy et al 2007). Another significant complication is an increased risk of cancer and greater difficulty in treating it (Arcasoy et al 2007). This is particularly true for patients receiving SLT that develop native lung cancer (Mac Adams et al 2001). In addition, all lung transplant recipients are at risk for post-transplant lym-phoproliferative disorder (especially if they are Epstein–Barr virus-negative) (Arcasoy and Kotloff 1999; Trulock et al 2007). There are other less common complications that will not be discussed further.
LVRS and lung transplantation offer appropriate options for patients with advanced COPD; no head-to-head trials have been performed, so the superiority of either one cannot be evaluated. Both lead to significant improvements in physiologic and quality of life outcomes. However, LVRS leads to smaller improvements, but with fewer potential side effects than transplantation. On the other hand, transplantation offers the most dramatic benefit. LVRS is usually appropriate for healthier patients and is not a contraindication for future lung transplantation. In general, patients eligible for the criteria described in the NETT trial should be offered that first. However, the decision should be individualized based on patient preferences, center expertise and potential risk and benefit of each procedure.

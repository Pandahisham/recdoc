Magnetoencephalography  as a Putative Biomarker for Alzheimer's Disease

Academic Editor: James B. Brewer
Alzheimer's Disease (AD) is the most common dementia in the elderly and is estimated to affect tens of millions of people worldwide.  AD is believed to have a prodromal stage lasting ten or more years. While amyloid deposits, tau filaments, and loss of brain cells are characteristics of the disease, the loss of dendritic spines and of synapses predate such changes. Popular preclinical detection strategies mainly involve cerebrospinal fluid biomarkers, magnetic resonance imaging, metabolic PET scans, and amyloid imaging. One strategy missing from this list involves neurophysiological measures, which might be more sensitive to detect alterations in brain function. The Magnetoencephalography International Consortium of Alzheimer's Disease arose out of the need to advance the use of Magnetoencephalography (MEG), as a tool in AD and pre-AD research. This paper presents a framework for using MEG in dementia research, and for short-term research priorities.

Alzheimer's disease (AD) is the major cause of clinical dementia in the elderly. As many as 35.6 million people worldwide may currently be living with dementia, with the prevalence increasing to 65.7 million by 2030 and 115.4 million by 2050; two thirds of these people will likely have AD  (http://www.alz.co.uk/research/files/WorldAlzheimerReport-ExecutiveSummary.pdf). The incidence and prevalence of AD begins to rise as individuals reach the age of 65 so that by the time they are in their 80 s and 90 s, the risk of clinical dementia is nearly 50%. However, in spite of the fact that the risk of the clinical syndrome, Alzheimer's dementia, is greatest in the later years of life, the pathological processes, Alzheimer's Disease, begin 10–20 or more years before clinical onset. This means that treatment strategies aimed at disease modification will be most efficacious if they can occur during the period when the pathological changes are occurring, but have not yet exhibited themselves as clinical signs and symptoms. 
Although the diagnostic criteria for AD have been well codified since the early 1980s [1–3], there has been a recent upsurge in interest in studying individuals who are in the transitional stage between normal cognition and full-blown dementia. This syndrome, referred to as Mild Cognitive Impairment (MCI) [4–9], has been the focus of intense study and there are many who believe that in the absence of other medical comorbidities, individuals with MCI, in fact, have clinical AD in its earliest stages [10–13]. 
At the same time, with the development of new biological technologies, there is an increased interest in adding biomarkers as a form of pathological confirmation of the clinical diagnosis of AD. The current research diagnostic standard—those of the NINCDS/ADRDA [1] gives a probabilistic estimate of the risk of pathological AD in the context of a clinical dementia syndrome. The final diagnosis of “Definite” AD can only be made in the presence of a sufficient number of senile plaques and neurofibrillary tangles, that is, a neuropathological examination is required [14–16]. In life, however, clinical diagnosis is rated in terms of a set of clear criteria that focus not only on core signs and symptoms, but also on the presence or absence of comorbid factors that could, in and of themselves, cause a dementia syndrome. In the absence of such comorbid conditions, an individual is thought to have “Probable” AD. When such conditions are present, then the certainty of diagnosis is reduced to the level of “Possible”. 
Recent attempts at reformulating the diagnostic criteria have focused on the potential utility of biomarkers including brain structural and functional imaging, cerebrospinal fluid measures of amyloid beta, and alterations in brain chemistry measured using positron emission tomography (PET) [17] (cf. [18]). Some biomarkers have shown excellent predictive validity relative to neuropathology including MRI measures of brain structural integrity, PET and measures of cerebral blood flow and metabolism. However, “(w)hether one of these measures or a combination of them is more sensitive than the other, and whether quantitative values provide more information than a dichotomous rating are yet to be determined conclusively” (http://www.alz.org/research/diagnostic_criteria/, accessed 09 Sep, 2010).
Biomarkers measured at the time of the diagnosis of AD are excellent in predicting the presence of pathology at the time of autopsy, 8–10 years later. However, they are less efficient at detecting the presence of pathological change prior to the onset of clinical symptoms (cf., [19, 20]). This could be due, in part, to the mechanisms of the initiation of the molecular cascade leading to amyloid deposition [21]. While PET imaging is particularly useful for measuring brain metabolism, alterations in amyloid deposits, and in neurochemistry, the temporal and spatial resolution of a PET scanner is such that it reduces its sensitivity to the very early and statistically small changes in brain function (See Figure 1). MRI has improved temporal and spatial resolution relative to PET, but we likely need higher temporal resolution than is afforded by MR techniques in order to identify the earliest functional changes of disease in the preclinical stage. Thus, it seems necessary to have a biomarker that (1) measures neuronal activity directly, (2) has good temporal and spatial resolution, and (3) is able to evaluate functional networks and the associated neuronal code (i.e., oscillatory activity).
One potential biomarker that has received relatively little attention is that of electrophysiological/biomagnetic changes in the brain. These measures are potentially very useful because although their spatial resolution is similar to that of MRI, their temporal resolution is as many as three orders of magnitude better than other existing functional tools. Furthermore, these techniques are noninvasive, measure neuronal activity directly, and provide valuable information regarding the frequency of oscillatory activity. Consequently, these measures may provide the best index of the earliest functional changes that may occur secondary to neuropathological processes, but prior to the onset of the clinical dementia syndrome. In order to be most effective, however, these markers must have predictive validity relative to the neuropathology of AD, as well as modest intra- and intersubject variability. And, they must be stable over reasonable time course (i.e., 3–6 months) in order to be useful to track change in disease, or response to medication. 
The application of electroencephalography (EEG) in the clinical evaluation of AD patients has a long tradition [22, 23], and it is now generally accepted that the EEG in mild AD is marked by an increase in theta activity, accompanied by a decrease in beta and alpha activity [24]; more severe AD is marked by an increase in delta power [25]. This pattern of results is referred to as the “slowing” of the AD patients' EEG [26, 27]. Further, it appears that differences in EEG abnormalities based on visual ratings may be associated with different cognitive profiles [28]. AD patients with normal EEGs show the best performance in cognitive tasks, and only a moderate memory disturbance. Those patients with focal abnormalities (sharp waves or focal slow-wave activity) had average performance on the cognitive tasks, with a moderate alteration in semantic verbal fluency and poor performance on the Trail-Making B test. Patients with diffuse slowing only (a dominant frequency below 8 Hz) showed the worst performance in all tasks.  Finally, AD patients with both focal and diffuse EEG abnormalities group showed good performance in episodic memory tasks and a significant deterioration in working memory and executive functions. 
EEG has also been investigated in MCI patients, and a similar pattern of slowing was found. Theta band power and coherence differs significantly between MCI patients and healthy subjects [29], and alpha and theta relative power in the left temporo-occipital derivation correctly classified 85% of MCI subjects who would later develop AD [30]. A more anterior localization of theta and alpha activity is also a good predictor of future development of AD from MCI [31]. Generally, however, MCI subjects tend to show intermediate EEG parameters between those of ADs and controls. There is a slowing of the spectral profile in GDS stage 3 (i.e., MCI subjects), as compared to controls [32]. Patients classified as GDS 4 or 5  (i.e. clinical dementia) have very similar profiles to MCI patients; only patients with moderate to severe dementia had a frequency pattern that was distinct from all other patients groups. Similarly, increases in theta and reductions in alpha power can distinguish AD patients and controls, but cannot distinguish between MCIs and controls [33]. MCI subjects' EEG parameters are not only intermediate between those of controls and AD, but also show a considerable overlap [27]. Babiloni and colleagues [34] have suggested that traditional EEG power spectrum and amplitude analysis might not be sensitive enough to differentiate MCI patients from healthy control subjects.
Another method of analysis, estimating coherence/synchronization, is an example of a technique that could improve classification of MCI. Coherence analysis is widely used and represents a normalized linear measure of the correlations between two signals as a function of frequency [35, 36]. There is a decrease in coherence values in alpha and beta bands in AD patients (for a review, see [27]). In the case of MCI, there is a decrease of intrahemispheric frontoparietal EEG coherence and an increase of temporal interhemispheric coherence compared to elderly controls. [37]. Synchronization likelihood (SL) [38] has  been used to study the brain activity in MCI, and was found to be significantly decreased in the 14–18 and 18–22 Hz bands in AD patients compared with both MCI subjects and healthy controls [39]. Unfortunately, SL was similar in the controls and MCI patients. 
Most of resting state EEG studies in MCI show a pattern of increased low-frequency activity accompanied by a decrease of coherence or synchronization. By contrast, activation studies tend to show increased SL. In a study of MCI patients at rest and performing a visual working memory task, significant differences between the patients and controls were found only in the alpha-2 band during the working memory condition (i.e., not at rest) [40]. Indeed, there is an increase in SL in MCI during the performance of a working memory task, and this increase was associated with the risk for the progression to AD [41]. These paradoxical findings may be related to a compensatory mechanism in the brain during the first stages of cognitive deterioration.
Although coherence and SL are probably two of the most broadly used estimates of EEG connectivity in AD, a variety of synchronization estimates are being used.  For example, Kramer and colleagues [42] compared phase synchrony and two measures of nonlinear interdependency in AD patients, MCI subjects, and healthy controls. Only phase synchrony and one of the nonlinear estimates allowed the discrimination of AD patients from controls, and AD and MCI subjects. None of the measures was capable of discriminating the MCI patients from the controls. Dauwels and collaborators [43] tested as many as 20 synchrony measures, on five minutes of resting EEG data in 25 MCI patients and 56 healthy controls. Overall, the MCI patients had lower synchronization values compared to controls, but only two were significant after correction for multiple comparisons. Those estimates were the so-called “Full frequency directed transfer function”, and the ρ parameter of the Stochastic event synchrony.  Although their pattern of results may be due to a disconnection syndrome in the AD patients, Dauwels and coworkers [43] highlighted the fact that their results could not be due to a disconnection syndrome alone (e.g., [44]); the AD patients showed not only a reduced synchrony but also an increase of asynchronous  activity.   
Thus, while EEG provides important information about AD, it does not appear adequate to detect preclinical disease. In this paper we will focus on the potential utility of magnetoencephalography (MEG) to detect functional changes in the brain secondary to AD pathology, prior to symptom onset. MEG is a sensitive tool for measuring magnetic fields that correspond to electrical currents in the brain, and that has been extremely useful for non-invasive studies of epilepsy. MEG technology was born 40 years ago [45] and has been used for more than 20 years within multimodal neuroimaging, but only relatively recently has it begun to be used more extensively in clinical and research settings.  
While it is true that MEG it is not a widespread technique, the number of MEG centers has increased dramatically in Europe and in America over the last ten years. In the past, the analysis of MEG data was difficult and required very specialized methods. More recently, equipment manufacturers have developed new software that is relatively user-friendly allowing physicians to analyze MEG data; there is new freeware (EEGlab; Brain Storm; SPM8, FieldTrip), and commercial products (Curry, BESA) are available, as well. It is still true that for advanced analysis such as connectivity or network analysis a high degree of analytic specialization is necessary, but this is a normal stage in the development of any newer technology.
MEG records activity in the brain based on the magnetic fields induced by synchronized neuronal currents [46, 47] and can monitor the activation of synchronously firing neuronal populations with a submillisecond temporal resolution [46–48].  However, since the magnetic signals of the brain vary between 102 (evoked cortical activity) and 103 femtoteslas (fT) (the human alpha rhythm), and the magnetic field of the earth is in the neighborhood of 109 fT, the method has to balance two problems: the weakness of the signal and the strength of the noise [47].  These issues are addressed by using hundreds of extremely sensitive superconducting quantum interference devices incorporated in the whole head system (for recording simultaneously from the entire brain) and used in a magnetically shielded room [47].
MEG has several advantages over other measures of electrical activity of the brain including its freedom from the requirement for a reference electrode which has the potential to improve calculations of the electrical power and source localization of the signal. Because there is no need for a reference point in MEG studies, this facilitates synchronization and coherence analyses. Connectivity measures and source reconstruction solutions depend to some extent on the positioning of the reference channels, thus the lack of a reference gives MEG an advantage over EEG. MEG uses many more detectors than traditional EEG sensor arrays in many machines, and this can obtain whole head coverage of signal very rapidly. Because magnetic fields are more transparent through biological tissue, high-frequency bands have better signal-to-noise ratios than EEG where electrical currents are affected by the resistance of biological tissues and distorted by the skull. This allows for better spatial resolution and thus better localization of the sources of electrical activity from MEG compared to EEG. The resistance of the biological tissues to electrical current also produces severe attenuation of the EEG signal in the case of the high-gamma band. MEG, on the other hand, is much more sensitive to this range of frequencies. In the last decade there is increasing evidence of the close relation between the gamma band and cognition. 
MEG has several potential advantages over functional MRI (fMRI), another potential biomarker for AD.  First, it has a much greater temporal resolution, and as one of the consequences of neurodegeneration is slowed mentation, this may mean that MEG is better able to measure such subtle delays in local and regional responses.  Second, by and large, metallic fragments in the body are not contra-indications for the scan, although if they are large, or are too close to the head they render the MEG signals too noisy. Having a 306-sensor, whole head system may allow for easier comprehensive spatial sampling and thus better suppression of interference, and advanced processing tools can reduce unwanted interference [49].  Third, and most important, is the fact that MEG does not rely on the hemodynamic response (see [50], for discussion). fMRI measures neuronal activity only indirectly. When a group of neurons become activated there is a local increase (about 4000 ms after the activation) in blood flow which makes it impossible to measure oscillatory activity in the most relevant frequency bands. It is the analysis of oscillatory activity afforded by MEG that allows for the estimation of phase synchronization indices between brain regions. Intracellular currents in large neuronal assemblies of at least ~104-5 pyramidal cells in parallel orientation can be measured more directly, providing “a more direct index of sensory, motor, and cognitive task-specific activation compared with methods that rely on hemodynamic measures” (page 869, [50]). 
One weakness of fMRI and PET activation paradigms is that the temporal resolution is (relatively) poor.  Even with a rapid fMRI design, the acquisition sums data over 1-2 seconds, and there is a delay of 4–6 seconds between the relevant neuronal event, and the peak BOLD response.  By contrast, MEG provides nearly simultaneous (with respect to the neuronal events) recording at >103 msec temporal resolution.  This means that subtle changes are more likely to be detected, and we have the opportunity for a more fine-grained analysis of functional connectivity (e.g., [51]). Alterations in signal characteristics may get lost in the noise of a 2 second acquisition of fMRI (i.e., TR = 2000), but may be easily detected with MEG. This high temporal resolution allows the measurement of the dynamics of the oscillatory activity, and as a consequence establishing the functional interaction between brain regions at specific frequency bands. Therefore, MEG provides a four-dimensional view of brain function (space time frequency connectivity) which offers a better description of the consequences of neurological diseases on the functional networks which support cognitive functions. MEG may have potential as a biomarker of AD, and we must evaluate the relative merits of the methodology in neurodegenerative disease.
As noted above, EEG measures of brain function have shown that the integrity of brain oscillatory activity is a good index of its functional state. Indeed, over the last several years, there has been an increase in interest in what is known as the “default mode network” which was first identified by using positron emission tomography (PET) and functional MRI [52]. Although clinical MRI scanners are now capable of routinely gathering resting state measures of cerebral blood flow, there is usually no analysis of functional networks during the “resting” state, as this requires offline processing (e.g., [53]). This is unfortunate because the “default mode” appears to be altered in cortical dementias [51, 54, 55] and such information could be useful diagnostically. While default mode networks detected with MRI oscillate below 0.5 Hz, resting state measures acquired in MEG can detect higher frequency oscillations. Dipole density or minimum current estimates have provided important information about cortical abnormalities that lead to the clinical progression of AD [56–58].  Although MEG is relatively less sensitive to subcortical abnormalities compared to cortical changes, it can assess function in ~70% of the fissural cortex, (due to the alignment of the cortical columns relative to the MEG sensors).  Thus, MEG has a high likelihood of detecting subtle alterations in cortical function [59].
MEG has already shown promise in terms of detecting AD in its earliest clinical stage (see [60, 61]). One study of 15 AD patients localized the generators of focal magnetic slow waves during an eyes-open resting condition using a simple dipole model [62]. There was an increase in the number of dipoles in the delta and theta bands, and significant slowing in brain electrical activity in the temporal and parietal regions of both hemispheres of the AD patients [63]. Critically, the slow-wave activity in the right temporal parietal regions varied as a function of degree of cognitive impairment, whereas the activity in the left temporal areas was associated with functional status [62]. The alterations in brain function that are detected with MEG, especially those in the temporal regions, are significantly correlated with the relative volume of the lateral and medial temporal lobes [64, 65]. This establishes a link between altered brain structure and altered brain function measured in two different modalities (i.e., MRI and MEG).
 MEG may also be useful in aiding with some of the differential diagnosis that occurs in the context of AD. Specifically, the “profile” of neuromagnetic activity measured using the event-related magnetic response in a memory task, includes significantly reduced activity in the left temporal lobe in AD patients. By contrast,  individuals with late onset depression, do not differ from nondemented cognitively normal elderly individuals [66, 67]. Thus, there seems to be some degree of specificity of the neuromagnetic abnormalities observed in AD.
 MEG shows particular promise in predicting the development of MCI from normal cognition. In a study of 15 healthy subjects, five of whom developed MCI two years later, those who showed cognitive decline had a lower number of activity sources (400–800 ms frequency range) in the left medial temporal lobe compared to the individuals who did not show cognitive decline [68]. Similarly, when individuals with MCI are studied after two years of followup, the relative risk of developing AD increased more than three times among those individuals who had significantly elevated number of dipole density scores in the delta frequency range [56]. Taken together these data demonstrate that MEG may not only be able to predict risk of developing AD from MCI, but may be able to detect brain functional abnormalities in cognitively normal individuals. Because MEG is non-invasive and does not involve the use of contrast agents or radiotracers, it can be easily repeated as often as necessary as a method for tracking disease progression.
Critical to understanding the relationships between brain function and cognition is the concept of functional connectivity. Brain function has been studied from the standpoint of functional segregation or specialization in an effort to localize cognitive functions in specific brain regions (see [69–71] for discussion). Modern views of brain organization, when coupled with more advanced statistical analysis techniques, have allowed us to study the relationship among brain regions and how they affect behavior [72], that is, the concept of functional integration studied with functional connectivity [73]. As such, brain networks represent complex systemic architecture, with a balance between segregation and integration of information. Functional connectivity refers to the statistical interdependence between neurophysiological data that is recorded simultaneously from a variety of different brain regions. 
Since the early days of modern research in the pathology of AD, there has been a discussion of concepts of disrupted connectivity among brain regions as being responsible for some of the earliest cognitive changes that occur in the disorder (e.g., [74]. This disruption of the anatomical/functional connections in AD led to the idea of a disconnection syndrome as being potentially responsible for much of the cognitive loss, at least early in the disease. This abnormality in functional connectivity suggests abnormal interactions between neural systems that typically interact to support cognition and behavior. Because the pathological changes associated with AD begin several decades before the onset of the clinical syndromes, it is important to evaluate whether the functional profiles are affected in the preclinical stages, including MCI, and even in the context of normal aging.
MEG provides data about three-dimensional space (space and time), as well as frequency bands, which allows us to address the question of which areas are functionally linked (i.e., connectivity), and at what point in the information processing stream the linkages occur. In MEG, the statistical correlation between two magnetic time series can be measured through linear and nonlinear methods including spectral coherence, phase synchronization, or generalized synchronization. Long-range synchronization between signals; that is, oscillatory activity, originating in relatively distant neuronal populations is one potential mechanism for communication and integration of information in the brain [75–77]. Thus, functional connectivity can be viewed as being closely related to the concept of synchrony which is the most common, economical, and biologically plausible mechanism for information communication in the brain.
In a recent series of papers examining visual working memory, Palva and colleagues have demonstrated how synchrony can support memory [78, 79]. In their studies, they mapped the dynamics of network synchrony during the performance of a memory task and found that there was sustained phase synchrony in parietal/frontal circuits in three frequency bands. Perhaps most important was the finding that the synchrony increased as a function of the memory load. They suggested that the synchrony among the various brain regions could reflect a compensatory mechanism to help deal with retention of information, when that information load rises above working memory “capacity” (usually in the range of 3-4 items). This is a provocative finding in the present context because the data suggests that there is some form of compensatory response possible in the early stages of MCI and AD [73, 80, 81].
Synchronization Likelihood (SL) has been used to differentiate between individuals with AD to subjects with no cognitive impairment in MEG [39, 51, 82]. These studies show, in general, a loss of long-distance synchronization in AD patients. In MCI, similar reductions in long-distance connections were also noted, even in a resting state. However during a memory task, patients with MCI showed increased SL values relative to healthy controls [83]. These latter data argue against MCI as a disconnection syndrome, but also must be viewed in the context that there is a functional compensatory response that occurs during the MCI phase [81].
 The earliest clinical indicators of potential alteration in brain function can often be symptoms of “subjective memory complaints” that are not accompanied by alterations in neuropsychological test performance.  Patients with subjective memory complaints showed higher MEG activation than control subjects in posterior ventral regions of the cortex, as well as in the parietal/occipital regions [84]. No statistically significant differences were found between patients with MCI and individuals with subjective memory complaints, indicating a certain degree of similarity between individuals with complaints of memory loss and those with documented alterations in cognitive functions. This suggests at a minimum that within the group of individuals with subjective memory complaints there are some who will progress to a stage of MCI and eventually AD [85]. Further, in the earliest preclinical stages of the dementia syndrome, MEG may be capable of detecting alterations in the functional organization of the central nervous system that indicate the existence of a degenerative process. 
AD is considered a disease of the cholinergic transmitter system. This is due in part to the fact that one of the earliest manifestations of AD pathology is a loss of cholinergic neurons arising from the nucleus basalis of Meynert in the basal forebrain [86, 87] which can be visualized in structural brain imaging [88–92]. Indeed, atrophy of the basal forebrain is a marker for rapid decline from normal cognition to dementia within four years [93]. Indeed, challenging the cholinergic system by the administration of scopolamine to cognitively healthy elders results in greater decline in memory than in younger individuals [94]. Critical to the present discussion is the fact that MEG studies have found that spontaneous brain activity and cortical auditory processing [95] which are impaired in AD, are themselves modulated by the scopolamine [96, 97]. Because MEG appears to be sensitive enough to detect short-term changes in brain activity by cholinergic modulation it may be useful as a biomarker for the modulation of the cholinergic system, or of the neural networks responsible for spontaneous background activity during the course of a typical pharmacological trial.
As in any other medical procedure MEG needs the cooperation of the patient to perform an accurate scan. Just like MRI and PET, patient movement inside the scanner produces a distortion of the images, which reduces the utility of the results. For MEG imaging, resting state studies with MEG require only that the subject is seated (or lying) in a comfortable position, and remains motionless; MEG manufacturers have developed head tracking systems to correct for any inadvertent movements. During cognitive tasks, it is necessary to acquire a large number of trials so that the data can be analyzed on a single subject basis, so there is a necessary tradeoff between time in the scanner and data acquisition. The large number of trials (normally 120 in a memory task) allows for an analysis of the within-subject reliability of the data (i.e., comparing the first half and second half of the trials), something not generally possible with PET or fMRI studies. 
Before the utility of MEG can be rigorously evaluated in AD and related dementias, there are some critical prerequisite data that need to be gathered, including determining the test-retest reliability, and the stability of the signal over time.  That is, in order for MEG to be useful in tracking the natural history of CNS function, or to be used in evaluating pharmacotherapy (for example), we must first understand the extent to which the data are reproducible, both over the short term (i.e., reliability) and longer term (i.e., stability).  Critically, high reliability and/or stability of the MEG response are necessary preconditions for MEG validity. Further, different centers must be able to identify the same biomagnetic signature in order for any putative biomarker to be useful.  Finally, it is equally important to analyze the reliability and stability of the behavioral task (e.g., the modified Sternberg probe task used in many MEG AD studies) itself. It is critical that the memory task (or other behavioral probe) is not only reliable, but that any changes in performance over time are also reflected by changes in the larger battery of neuropsychological tests (i.e., concurrent validity).
To date, the bulk of clinically relevant MEG research uses activation protocols focusing either on somatosensory functions (e.g., [98]) or, more prominently, language tasks used in the context of presurgical functional localization studies [99].  A (relatively) early review of the field [100] found that MEG was generally reliable and valid (relative to sodium amytal studies), while source localization varies within a range of 1.5–3 mm [100] which is less than one voxel of MRI data. MEG signal reliability for a single region was rho = .42, and the median correlation across more than 20 regions was .61 (with only one region having a correlation less than .50) [101].  Thus, at least for language-based tasks, the ability to localize MEG signal appears good [99].
Once the reliability and stability of MEG are established for these tasks and patient groups, there must be a demonstration that a specific “signature” of AD has concurrent validity with other known biomarkers such as brain structural and cerebral metabolism (and amyloid imaging) (e.g., [65]). In addition, there should be predictive validity in that the presence of an abnormality identified by MEG should correlate with pathological changes in AD identified at autopsy.  
Because MEG has only recently been applied to the study of neurodegenerative diseases, there are relatively few centers with the capability and interest in studying the potential utility of MEG. These centers are widely distributed around the world adding to the logistic complexity of completing a study of reliability and stability. However, if such a cross-center study could be accomplished, this would result in increased generalizability of the findings as they would have been acquired on different machines in different countries using different at-risk populations. 
Given this background, we recently formed an international collaborative group for the study of the utility of MEG for the preclinical detection of AD. This collaborative group has the potential to validate previous findings with MEG, and to demonstrate the suitability of including MEG in the study of the earliest diagnosis and detection of AD and related dementias. Three of the centers have extensive experience studying the capability of MEG in differentiating between healthy aging and AD, and as a consequence of this research there are several principal findings that could potentially serve as signature biomarkers. These include (1) a delay in the latency of the N100 m signal which is an index of stimulus detection; (2) a delay in the mismatch negativity in auditory cortex as a measure of automatic stimulus detection and delay of memory trace; (3) an increase in parietal activity in the delta frequency band in posterior cortical regions; (4) a reduced number of biomagnetic sources in the posterior cortical regions during performance of memory tasks; (5) higher local SL value but lower long-distance SL values in spontaneous (i.e., resting) brain activity. 
As a first step in the process of determining the reliability and validity of MEG in the diagnosis of AD, the collaborative group will determine the cross-center reliability of measuring biomagnetic signal using standardized techniques, on the same model equipment, from the same equipment manufacturer.  The protocol includes both resting state (eyes open, eyes closed), a memory probe task and a mismatch-negativity task [102].  In addition, all of the subjects will undergo high-resolution MRI, including anatomical sequences (i.e., MP-RAGE) as well as those to identify white matter abnormalities (e.g., FLAIR, DTI). All of the data will be sent to a central analysis center (Madrid) where they will be processed (blind) and the results recombined by an independent data analyst in order to determine center-to-center reliability. Signal analysis will also be conducted independently in Helsinki. The data will then be analyzed in an attempt to replicate not only at a group level, but also a single subject level. Of particular interest is the extent to which it is possible to use classification algorithms based on comparing AD patients and control subjects in order to identify MCI in the context of healthy aging, something that will be spearheaded from Pittsburgh (e.g., [103]). 
Having established the inter- and intracenter variability, we will have established a necessary precondition for studies of concurrent validity relative to the clinical diagnosis, and to standard measures of brain structural abnormalities (e.g., decreased volume of the hippocampus). Having established these initial standards, only then it will be possible to embark on large-scale multicenter trials to fully examine the relative merits of MEG in the diagnosis and early detection of neurodegenerative pathologies.  
Because MEG is a relatively new neuroimaging technology and is used extensively only in centers with significant research operations, it is necessary to establish these criteria not only on a multisite basis, but also a multinational basis. No single center will have sufficient cases or the analytic wherewithal to complete the process in isolation. It is only by virtue of these multinational collaborative efforts that MEG can be fairly evaluated for potential use in AD.
